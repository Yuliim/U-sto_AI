import os
import json
import glob
import sys
import io
import re
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv
import os
# =======
# ì´ìœ 

# - ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„
# - RAG ingestion íŒŒì´í”„ë¼ì¸ì˜ ì¼ë¶€
# ==========================================
# ğŸ”‡ [ì¹¨ë¬µ ëª¨ë“œ] í™”ë©´ ì¶œë ¥ ì¸ì½”ë”© ê°•ì œ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding='utf-8')
# ==========================================

# ğŸš¨ [í•„ìˆ˜] ìœˆë„ìš° ì‚¬ìš©ì ì´ë¦„ ì˜¤ë¥˜ ë°©ì§€
os.environ["USERNAME"] = "User"
os.environ["USER"] = "User"

# # ğŸ”‘ [í•„ìˆ˜] API í‚¤ ì…ë ¥ (ë³¸ì¸ í‚¤ í™•ì¸!) -> í‚¤ ê°€ì ¸ì˜¤ê¸°ë¡œ ë°”ê¿¨ìŠµë‹ˆë‹¤.
# os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
### ìœ„ì— ì½”ë“œëŒ€ë¡œë©´ â€œ.envëŠ” ìˆëŠ”ë°, loadë¥¼ ì•ˆ í•œ ìƒíƒœì—ì„œ Noneì„ ê°•ì œë¡œ ë„£ì€ ê²ƒâ€ì´ë¼ ë¶ˆí•„ìš”í•œ ì½”ë“œ+ì‹¤í–‰ì•ˆë˜ëŠ”ì½”ë“œ
load_dotenv()  # .env íŒŒì¼ì„ os.environì— ë¡œë“œ (ì •ì„ ë°©ë²•)


INPUT_FOLDER = 'dataset/input'
OUTPUT_FOLDER = 'dataset/qa_output'

def extract_json_from_text(text):
    """
    AI ì‘ë‹µì—ì„œ ìˆœìˆ˜ JSON ë¶€ë¶„ë§Œ ë°œë¼ë‚´ëŠ” ê°•ë ¥í•œ í•¨ìˆ˜
    """
    try:
        # 1. ê°€ì¥ ì‰¬ìš´ ê²½ìš°: ê·¸ëƒ¥ ë°”ë¡œ ë³€í™˜ ì‹œë„
        return json.loads(text)
    except json.JSONDecodeError:
        try:
            # 2. Markdown ì½”ë“œë¸”ë¡ ì œê±° (```json ... ```)
            text = text.replace("```json", "").replace("```", "").strip()
            return json.loads(text)
        except json.JSONDecodeError:
            try:
                # 3. ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ { ... } êµ¬ê°„ë§Œ ê°•ì œë¡œ ì¶”ì¶œ
                match = re.search(r'\{.*\}', text, re.DOTALL)
                if match:
                    json_str = match.group()
                    return json.loads(json_str)
            except:
                pass
    return None

def convert_content_to_qa():
    print("ğŸš€ Smart Converting Started...") 

    if not os.path.exists(OUTPUT_FOLDER):
        os.makedirs(OUTPUT_FOLDER)

    # temperature=0.1 : ì°½ì˜ì„±ì„ ì¤„ì´ê³  í˜•ì‹ì„ ë” ì˜ ì§€í‚¤ê²Œ í•¨
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0.1)
    input_files = glob.glob(os.path.join(INPUT_FOLDER, '*.json'))

    if not input_files:
        print("Error: No input files found.")
        return

    print(f"Found {len(input_files)} files. Processing...")

    for file_path in input_files:
        file_name = os.path.basename(file_path)
        print(f"\nProcessing File: {input_files.index(file_path) + 1}/{len(input_files)} ({file_name})")

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            new_qa_data = []
            total_items = len(data)

            for idx, item in enumerate(data):
                try:
                    # ë°ì´í„° í…ìŠ¤íŠ¸í™”
                    if isinstance(item, dict):
                        title = item.get('title', '')
                        content = item.get('content', '')
                        # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´(10ì ë¯¸ë§Œ) ê±´ë„ˆë›°ê¸° (ë¶ˆí•„ìš”í•œ ì—ëŸ¬ ë°©ì§€)
                        full_text = f"{title} {content}".strip()
                        if len(full_text) < 10:
                            print(f"   [SKIP] Item {idx+1} (Too short)")
                            continue
                            
                        input_text = f"Title: {title}\nContent: {content}"
                    else:
                        input_text = str(item)
                        if len(input_text) < 10:
                             print(f"   [SKIP] Item {idx+1} (Too short)")
                             continue

                    # í”„ë¡¬í”„íŠ¸ ê°•í™”: ë¬´ì¡°ê±´ JSONë§Œ ë±‰ìœ¼ë¼ê³  í˜‘ë°•(?)
                    prompt_text = f"""
                    You are a data converter. 
                    Read the text below and create ONE question and answer pair in Korean.
                    
                    RULES:
                    1. Output MUST be valid JSON format only.
                    2. Keys must be "question" and "answer".
                    3. Do not add any explanation or markdown. Just the JSON.
                    
                    [Source Text]:
                    {input_text[:1500]} 
                    """

                    # AI í˜¸ì¶œ
                    response = llm.invoke([
                        SystemMessage(content="Output valid JSON only. No markdown."),
                        HumanMessage(content=prompt_text)
                    ])

                    # ê²°ê³¼ ì¶”ì¶œ (ê°•ë ¥í•œ í•¨ìˆ˜ ì‚¬ìš©)
                    qa_dict = extract_json_from_text(response.content)

                    if qa_dict and "question" in qa_dict and "answer" in qa_dict:
                        final_data = {
                            "question": qa_dict.get("question", ""),
                            "answer": qa_dict.get("answer", ""),
                            "source": file_name
                        }
                        new_qa_data.append(final_data)
                        print(f"   [OK] Item {idx+1}/{total_items} success.")
                    else:
                        # JSON êµ¬ì¡°ëŠ” ì•„ë‹ˆì§€ë§Œ ì‘ë‹µì€ ì™”ì„ ë•Œ
                        print(f"   [FAIL] Item {idx+1} JSON Parsing Error.")

                except Exception as e:
                    # ì§„ì§œ ë„¤íŠ¸ì›Œí¬/API ì—ëŸ¬ì¸ ê²½ìš°
                    print(f"   [ERROR] Item {idx+1} API/System Error.")

            # íŒŒì¼ ì €ì¥
            if new_qa_data:
                output_path = os.path.join(OUTPUT_FOLDER, file_name)
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(new_qa_data, f, ensure_ascii=False, indent=2)
                print(f"   --> Saved {len(new_qa_data)} items to file.")
            else:
                print("   --> No valid data to save.")

        except Exception as e:
            print("   --> File Read Error (Skipped)")

    print("\nAll Done! Check 'dataset/qa_output' folder.")

if __name__ == "__main__":
    convert_content_to_qa()