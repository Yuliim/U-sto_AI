import pandas as pd
import numpy as np
import os
from datetime import datetime

# ---------------------------------------------------------
# 0. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOAD_DIR = os.path.join(BASE_DIR, "data_lifecycle")
SAVE_DIR = os.path.join(BASE_DIR, "data_ml")
os.makedirs(SAVE_DIR, exist_ok=True)

print("ğŸ“‚ [Phase 4] AI í•™ìŠµìš© ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")

# 1. ë°ì´í„° ë¡œë“œ (ëª¨ë“  ìƒì• ì£¼ê¸° ë°ì´í„°)
try:
    df_op = pd.read_csv(os.path.join(LOAD_DIR, '04_01_operation_master.csv')) # ìš´ìš©
    df_rt = pd.read_csv(os.path.join(LOAD_DIR, '04_03_return_list.csv'))      # ë°˜ë‚©
    df_du = pd.read_csv(os.path.join(LOAD_DIR, '05_01_disuse_list.csv'))      # ë¶ˆìš©
    df_dp = pd.read_csv(os.path.join(LOAD_DIR, '06_01_disposal_list.csv'))    # ì²˜ë¶„
    print(f"   - ì›ì²œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(df_op)}ê±´")
except FileNotFoundError as e:
    print(f"âŒ ë°ì´í„° íŒŒì¼ ëˆ„ë½: {e}")
    exit()

# ---------------------------------------------------------
# 1. ë°ì´í„° ë³‘í•© (Master Table ìƒì„±)
# ---------------------------------------------------------
print("   1. ìƒì• ì£¼ê¸° ë³‘í•© (ìš´ìš©+ë°˜ë‚©+ë¶ˆìš©+ì²˜ë¶„)...")

# (1) ìš´ìš© + ë°˜ë‚© (Left Join) -> ë°˜ë‚©ì¼ì, ë°˜ë‚©ì‚¬ìœ (ìƒíƒœë³€í™”) í™•ë³´
# ë°˜ë‚©ë‚´ì—­ì˜ 'ì‚¬ìœ 'ëŠ” 'ìƒíƒœë³€í™”'ë¡œ ë§¤í•‘ (1ìˆœìœ„ ì‚¬ìœ )
df_merged = pd.merge(df_op, df_rt[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë°˜ë‚©ì¼ì', 'ì‚¬ìœ ']], on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
df_merged.rename(columns={'ì‚¬ìœ ': 'ìƒíƒœë³€í™”'}, inplace=True) 

# (2) + ë¶ˆìš© (Left Join) -> ë¶ˆìš©ì¼ì, ë¶ˆìš©ì‚¬ìœ  í™•ë³´
df_merged = pd.merge(df_merged, df_du[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë¶ˆìš©ì¼ì', 'ì‚¬ìœ ']], on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
df_merged.rename(columns={'ì‚¬ìœ ': 'ë¶ˆìš©ì‚¬ìœ '}, inplace=True)

# (3) + ì²˜ë¶„ (Left Join) -> ì²˜ë¶„ë°©ì‹, ë¬¼í’ˆìƒíƒœ í™•ë³´
# ì²˜ë¶„ë‚´ì—­ì˜ 'ì²˜ë¶„êµ¬ë¶„' -> 'ì²˜ë¶„ë°©ì‹'
df_merged = pd.merge(df_merged, df_dp[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì²˜ë¶„ë°©ì‹', 'ë¬¼í’ˆìƒíƒœ']], on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
df_merged.rename(columns={'ì²˜ë¶„êµ¬ë¶„': 'ì²˜ë¶„ë°©ì‹'}, inplace=True)

# ---------------------------------------------------------
# 2. ì¹¼ëŸ¼ ë§¤í•‘ ë° íŒŒìƒë³€ìˆ˜ ìƒì„± (Feature Engineering)
# ---------------------------------------------------------
print("   2. íŒŒìƒë³€ìˆ˜ ìƒì„± ë° ì¹¼ëŸ¼ ì •ì˜ ì ìš©...")

# [ë‚ ì§œ ì²˜ë¦¬ ë° ê¸°ì¤€ì¼ ì„¤ì •]
date_cols = ['ì·¨ë“ì¼ì', 'ë°˜ë‚©ì¼ì', 'ë¶ˆìš©ì¼ì']
for col in date_cols:
    df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')

# ê¸°ì¤€ì¼: ìì‚°ì˜ ìˆ˜ëª… ê³„ì‚° ì¢…ë£Œ ì‹œì 
# ì¢…ë£Œëœ ìì‚°(ë°˜ë‚©/ë¶ˆìš©)ì€ í•´ë‹¹ ì¼ì, ìš´ìš© ì¤‘ì¸ ìì‚°ì€ ì˜¤ëŠ˜ ë‚ ì§œ
today = pd.to_datetime(datetime.now().date())
df_merged['ìµœì¢…ì¢…ë£Œì¼'] = df_merged['ë°˜ë‚©ì¼ì'].combine_first(df_merged['ë¶ˆìš©ì¼ì'])
df_merged['ê¸°ì¤€ì¼'] = df_merged['ìµœì¢…ì¢…ë£Œì¼'].fillna(today)

# [DataFrame ì´ˆê¸°í™”] ì •ì˜ì„œ ìˆœì„œëŒ€ë¡œ ë°ì´í„° êµ¬ì„±
df_final = pd.DataFrame()

# --- A. ì •ì  ì •ë³´ (Static Features) ---
df_final['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'] = df_merged['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸']
df_final['G2Bëª©ë¡ëª…'] = df_merged['G2B_ëª©ë¡ëª…']
df_final['ë¬¼í’ˆë¶„ë¥˜ëª…'] = df_merged.get('ë¬¼í’ˆë¶„ë¥˜ëª…', df_merged['G2B_ëª©ë¡ëª…']) # ë¶„ë¥˜ëª… ì—†ìœ¼ë©´ ëª©ë¡ëª… ì‚¬ìš©
df_final['ë‚´ìš©ì—°ìˆ˜'] = df_merged['ë‚´ìš©ì—°ìˆ˜']
df_final['ì·¨ë“ê¸ˆì•¡'] = df_merged['ì·¨ë“ê¸ˆì•¡']
df_final['ìš´ìš©ë¶€ì„œì½”ë“œ'] = df_merged['ìš´ìš©ë¶€ì„œì½”ë“œ']
df_final['ì·¨ë“ì¼ì'] = df_merged['ì·¨ë“ì¼ì']
df_final['ë°˜ë‚©ì¼ì'] = df_merged['ë°˜ë‚©ì¼ì']
df_final['ë¶ˆìš©ì¼ì'] = df_merged['ë¶ˆìš©ì¼ì']
df_final['ìƒíƒœë³€í™”'] = df_merged['ìƒíƒœë³€í™”'] # 1ìˆœìœ„ ì‚¬ìœ  (ë°˜ë‚©ì‚¬ìœ )
df_final['ë¶ˆìš©ì‚¬ìœ '] = df_merged['ë¶ˆìš©ì‚¬ìœ '] # 2ìˆœìœ„ ì‚¬ìœ 
df_final['ë¬¼í’ˆìƒíƒœ'] = df_merged['ë¬¼í’ˆìƒíƒœ'] # ì²˜ë¶„ ì‹œ ë¬¼ë¦¬ì  ë“±ê¸‰
df_final['ì²˜ë¶„ë°©ì‹'] = df_merged['ì²˜ë¶„ë°©ì‹']
df_final['ìš´ìš©ë¶€ì„œëª…'] = df_merged['ìš´ìš©ë¶€ì„œ']
df_final['ìº í¼ìŠ¤'] = df_merged['ìº í¼ìŠ¤']
df_final['ì„œë¹„ìŠ¤ê³„ìˆ˜'] = 1.65 # 95% ì‹ ë¢°ìˆ˜ì¤€ Zê°’ (ìƒìˆ˜)

# --- B. íŒŒìƒ ë³€ìˆ˜ (Derived Features) ---

# (1) ìš´ìš©ì—°ì°¨ (Years Used)
# ê³µì‹: (ê¸°ì¤€ì¼ - ì·¨ë“ì¼ì) / 365
days_diff = (df_merged['ê¸°ì¤€ì¼'] - df_merged['ì·¨ë“ì¼ì']).dt.days
df_final['ìš´ìš©ì—°ì°¨'] = (days_diff / 365.0).round(2)
# ìŒìˆ˜ ê°’(ë¯¸ë˜ ì·¨ë“ ë“± ì˜¤ë¥˜) ë³´ì •
df_final['ìš´ìš©ì—°ì°¨'] = df_final['ìš´ìš©ì—°ì°¨'].apply(lambda x: x if x > 0 else 0.0)

# (2) í•™ìŠµë°ì´í„°ì—¬ë¶€
# ê¸°ê³„ì  ìˆ˜ëª…ì´ ë‹¤í•œ ê²ƒë§Œ í•™ìŠµ('Y'). ë‹¨ìˆœ ë§¤ê°ì´ë‚˜ í˜„ì¬ ìš´ìš© ì¤‘ì¸ ê²ƒì€ ì˜ˆì¸¡ ëŒ€ìƒ('N')
is_mech_end = df_final['ì²˜ë¶„ë°©ì‹'].isin(['íê¸°', 'ë©¸ì‹¤'])
df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] = np.where(is_mech_end, 'Y', 'N')

# (3) ì”ì—¬ë‚´ìš©ì—°ìˆ˜
df_final['ì”ì—¬ë‚´ìš©ì—°ìˆ˜'] = (df_final['ë‚´ìš©ì—°ìˆ˜'] - df_final['ìš´ìš©ì—°ì°¨']).round(2)

# (4) ë¶€ì„œê°€í˜¹ë„ (Department Severity)
# í…ìŠ¤íŠ¸ ë¶„ì„ì„ í†µí•´ ê°€ì¤‘ì¹˜ ë¶€ì—¬
def get_severity(dept_name):
    if pd.isna(dept_name): return 1.0
    dept_str = str(dept_name)
    # ê³ ë¶€í•˜ ë¶€ì„œ (IT, ê³µí•™, ì—°êµ¬)
    if any(k in dept_str for k in ['ì†Œí”„íŠ¸ì›¨ì–´', 'ê³µí•™', 'ì „ì‚°', 'AI', 'ì •ë³´', 'ì»´í“¨í„°']):
        return 1.3
    # ì¤‘ë¶€í•˜ ë¶€ì„œ (ì—°êµ¬ì‹¤, ì‹¤í—˜ì‹¤)
    if 'ì—°êµ¬' in dept_str or 'ì‹¤í—˜' in dept_str:
        return 1.2
    # ì¼ë°˜ í–‰ì •
    return 1.0

df_final['ë¶€ì„œê°€í˜¹ë„'] = df_final['ìš´ìš©ë¶€ì„œëª…'].apply(get_severity)

# (5) ëˆ„ì ì‚¬ìš©ë¶€í•˜
df_final['ëˆ„ì ì‚¬ìš©ë¶€í•˜'] = (df_final['ìš´ìš©ì—°ì°¨'] * df_final['ë¶€ì„œê°€í˜¹ë„']).round(2)

# (6) ê³ ì¥ì„ë°•ë„ (Failure Imminence, 0.0~1.0)
# ê³µì‹: (ìš´ìš©ì—°ì°¨ / ë‚´ìš©ì—°ìˆ˜)^2 í˜•íƒœë¡œ ì§€ìˆ˜í•¨ìˆ˜ì  ì¦ê°€ ëª¨ì‚¬
ratio = df_final['ìš´ìš©ì—°ì°¨'] / df_final['ë‚´ìš©ì—°ìˆ˜']
df_final['ê³ ì¥ì„ë°•ë„'] = (ratio ** 2).clip(0, 1).round(2)

# (7) ê°€ê²©ë¯¼ê°ë„ (Price Sensitivity)
# Log ë³€í™˜ í›„ ì •ê·œí™” (ìµœëŒ€ 1ì–µ ì› ê¸°ì¤€)
log_price = np.log1p(df_final['ì·¨ë“ê¸ˆì•¡'])
max_log_price = np.log1p(100000000) 
df_final['ê°€ê²©ë¯¼ê°ë„'] = (log_price / max_log_price).clip(0, 1).round(2)

# (8) ë¦¬ë“œíƒ€ì„ë“±ê¸‰ (0, 1, 2)
# 0: <500ë§Œ (ì¦‰ì‹œ), 1: <3000ë§Œ (ìˆ˜ì˜ê³„ì•½/ì…ì°°), 2: >=3000ë§Œ (ë³µì¡í•œ ì¡°ë‹¬)
def get_lead_time_grade(price):
    if price < 5000000: return 0
    elif price < 30000000: return 1
    else: return 2
df_final['ë¦¬ë“œíƒ€ì„ë“±ê¸‰'] = df_final['ì·¨ë“ê¸ˆì•¡'].apply(get_lead_time_grade)

# (9) ì¥ë¹„ì¤‘ìš”ë„
# (ê°€ê²©ë¯¼ê°ë„ * 0.7) + (ë¦¬ë“œíƒ€ì„ë“±ê¸‰ ê°€ì¤‘ì¹˜ * 0.3)
# ë¦¬ë“œíƒ€ì„ë“±ê¸‰ì€ 0~2ì´ë¯€ë¡œ 0.5ë¥¼ ê³±í•´ 0~1 ìŠ¤ì¼€ì¼ë¡œ ëŒ€ëµ ë§ì¶¤
df_final['ì¥ë¹„ì¤‘ìš”ë„'] = ((df_final['ê°€ê²©ë¯¼ê°ë„'] * 0.7) + ((df_final['ë¦¬ë“œíƒ€ì„ë“±ê¸‰'] * 0.5) * 0.3)).round(2)

# --- C. ì˜ˆì¸¡ê°’/ê²°ê³¼ê°’ (Placeholder) ---
# AI ëª¨ë¸ ì¶”ë¡  ì „ì´ë¯€ë¡œ ì´ˆê¸°ê°’ ì„¤ì •

# (1) ì‹¤ì œì”ì—¬ìˆ˜ëª… [ì •ë‹µì§€]
# í•™ìŠµìš© ë°ì´í„°(Y)ì¸ ê²½ìš°: ìˆ˜ëª…ì´ ë‹¤í–ˆìœ¼ë¯€ë¡œ ì”ì—¬ìˆ˜ëª…ì€ 0 (í˜¹ì€ ì‹¤ì œ ìˆ˜ëª… - ì‚¬ìš© ìˆ˜ëª…ì¸ë°, ì—¬ê¸°ì„  ì‹œì  ê¸°ì¤€ 0ìœ¼ë¡œ ìˆ˜ë ´)
# ì‹¤ì œ íšŒê·€ í•™ìŠµì‹œì—ëŠ” (ì‚¬ë§ì‹œì  - ê´€ì¸¡ì‹œì )ì´ Labelì´ ë˜ì§€ë§Œ, Master Tableì—ì„œëŠ” 0ìœ¼ë¡œ í‘œê¸°
df_final['ì‹¤ì œì”ì—¬ìˆ˜ëª…'] = np.where(df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y', 0, np.nan)

# (2) ì˜ˆì¸¡ ë° ì¬ê³  ê´€ë ¨ í•„ë“œ (ì´ˆê¸°í™”)
df_final['ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…'] = np.nan            # ëª¨ë¸ ì˜ˆì¸¡ í›„ ì±„ì›€
df_final['(ì›”ë³„)ê³ ì¥ì˜ˆìƒìˆ˜ëŸ‰'] = 0           # ì§‘ê³„ í›„ ì±„ì›€
df_final['ì•ˆì „ì¬ê³ '] = 0                     # Demand Forecasting í›„ ì±„ì›€
df_final['í•„ìš”ìˆ˜ëŸ‰'] = 0                     # ê³ ì¥ì˜ˆìƒ + ì•ˆì „ì¬ê³ 
df_final['AIì˜ˆì¸¡ê³ ì¥ì¼'] = pd.NaT            # ê¸°ì¤€ì¼ + ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…
df_final['ì•ˆì „ë²„í¼'] = 0.0                   # ëª¨ë¸ ì˜¤ì°¨(RMSE) ê¸°ë°˜ ì„¤ì •
df_final['ê¶Œì¥ë°œì£¼ì¼'] = pd.NaT              # ì˜ˆì¸¡ê³ ì¥ì¼ - ë¦¬ë“œíƒ€ì„
df_final['ì˜ˆì¸¡ì‹¤í–‰ì¼ì'] = today             # ì˜¤ëŠ˜ ë‚ ì§œ

# ---------------------------------------------------------
# [New] 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (Imputation)
# ---------------------------------------------------------
# 1) ì·¨ë“ê¸ˆì•¡ ê²°ì¸¡/0ì›: ì¤‘ì•™ê°’(Median) ëŒ€ì²´ - í‰ê· ë³´ë‹¤ ì´ìƒì¹˜ ì˜í–¥ì„ ëœ ë°›ìŒ
median_price = df_final[df_final['ì·¨ë“ê¸ˆì•¡'] > 0]['ì·¨ë“ê¸ˆì•¡'].median()
df_final['ì·¨ë“ê¸ˆì•¡'] = df_final['ì·¨ë“ê¸ˆì•¡'].fillna(median_price).replace(0, median_price)

# 2) ë‚´ìš©ì—°ìˆ˜ ê²°ì¸¡: ìµœë¹ˆê°’(Mode) ëŒ€ì²´
mode_life = df_final['ë‚´ìš©ì—°ìˆ˜'].mode()[0]
df_final['ë‚´ìš©ì—°ìˆ˜'] = df_final['ë‚´ìš©ì—°ìˆ˜'].fillna(mode_life)

# 3) í•µì‹¬ ë‚ ì§œ(ì·¨ë“ì¼ì) NaT: ì‚­ì œ (ìƒì• ì£¼ê¸° ê³„ì‚° ë¶ˆê°€)
initial_len = len(df_final)
df_final = df_final.dropna(subset=['ì·¨ë“ì¼ì'])
print(f"    - ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ì·¨ë“ì¼ì ëˆ„ë½ {initial_len - len(df_final)}ê±´ ì‚­ì œë¨")

# ---------------------------------------------------------
# [New] 2. íŒŒìƒ ë³€ìˆ˜ ë° í˜•ë³€í™˜ (Date -> Month)
# ---------------------------------------------------------
# (1) ìš´ìš©ì—°ì°¨ & ìš´ìš©ì›”ìˆ˜ (í˜•ë³€í™˜)
days_diff = (df_merged.loc[df_final.index, 'ê¸°ì¤€ì¼'] - df_final['ì·¨ë“ì¼ì']).dt.days
df_final['ìš´ìš©ì—°ì°¨'] = (days_diff / 365.0).round(2)
df_final['ìš´ìš©ì›”ìˆ˜'] = (days_diff / 30.0).astype(int) # [New] ì›” ë‹¨ìœ„ ì •ìˆ˜ ë³€í™˜

# (2) ì·¨ë“ì›” (ê³„ì ˆì„± ë°˜ì˜ìš©)
df_final['ì·¨ë“ì›”'] = df_final['ì·¨ë“ì¼ì'].dt.month # [New]

# (3) í•™ìŠµë°ì´í„°ì—¬ë¶€ ì •ì˜
is_mech_end = df_final['ì²˜ë¶„ë°©ì‹'].isin(['íê¸°', 'ë©¸ì‹¤'])
df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] = np.where(is_mech_end, 'Y', 'N')

# (4) ê¸°íƒ€ íŒŒìƒ ë³€ìˆ˜
def get_severity(dept_name):
    dept_str = str(dept_name)
    if any(k in dept_str for k in ['ì†Œí”„íŠ¸ì›¨ì–´', 'ê³µí•™', 'ì „ì‚°', 'AI']): return 1.3
    if 'ì—°êµ¬' in dept_str: return 1.2
    return 1.0

df_final['ë¶€ì„œê°€í˜¹ë„'] = df_final['ìš´ìš©ë¶€ì„œëª…'].apply(get_severity)
df_final['ëˆ„ì ì‚¬ìš©ë¶€í•˜'] = (df_final['ìš´ìš©ì—°ì°¨'] * df_final['ë¶€ì„œê°€í˜¹ë„']).round(2)

log_price = np.log1p(df_final['ì·¨ë“ê¸ˆì•¡'])
df_final['ê°€ê²©ë¯¼ê°ë„'] = (log_price / np.log1p(100000000)).clip(0, 1).round(2)

# ---------------------------------------------------------
# [New] 3. ì´ìƒì¹˜ ì œê±° (Outlier Removal)
# ---------------------------------------------------------
print("   3. ì´ìƒì¹˜ ì œê±° ìˆ˜í–‰...")
before_cnt = len(df_final)

# 1) ë…¼ë¦¬ì  ì´ìƒì¹˜: ìš´ìš©ì—°ì°¨ê°€ ìŒìˆ˜ì¸ ê²½ìš° (ì·¨ë“ì¼ > ê¸°ì¤€ì¼)
df_final = df_final[df_final['ìš´ìš©ì—°ì°¨'] >= 0]

# 2) í†µê³„ì  ì´ìƒì¹˜: ì·¨ë“ê¸ˆì•¡ ìƒìœ„ 0.1% ì œê±° (ì™œê³¡ ë°©ì§€)
# ë‹¨, í•™ìŠµë°ì´í„°(Y)ì™€ ì˜ˆì¸¡ë°ì´í„°(N) ëª¨ë‘ ì ìš©
q999 = df_final['ì·¨ë“ê¸ˆì•¡'].quantile(0.999)
df_final = df_final[df_final['ì·¨ë“ê¸ˆì•¡'] <= q999]

print(f"    - ì´ìƒì¹˜ ì œê±°: {before_cnt - len(df_final)}ê±´ ì œê±°ë¨ (ìŒìˆ˜ ì—°ì°¨ ë˜ëŠ” ì´ˆê³ ê°€ ìì‚°)")

# ---------------------------------------------------------
# 3. ë°ì´í„° ë¶„í•  (Time Series Split 7:2:1)
# ---------------------------------------------------------
print("   4. ì‹œê³„ì—´ ê¸°ì¤€ ë°ì´í„° ë¶„í•  (Train/Valid/Test)...")

# í•™ìŠµìš© ë°ì´í„°(Y)ë§Œ ë¶„í•  ëŒ€ìƒ
df_train_source = df_final[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y'].copy()
df_pred_source = df_final[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'N'].copy() # ì˜ˆì¸¡ ëŒ€ìƒ

# ì‹œê°„ ìˆœ ì •ë ¬
df_train_source = df_train_source.sort_values(by='ì·¨ë“ì¼ì')

# ë¶„í•  ì¸ë±ìŠ¤ ê³„ì‚°
n_total = len(df_train_source)
n_train = int(n_total * 0.7)
n_valid = int(n_total * 0.2)
# n_testëŠ” ë‚˜ë¨¸ì§€

# ë°ì´í„° ìŠ¬ë¼ì´ì‹±
train_set = df_train_source.iloc[:n_train]
valid_set = df_train_source.iloc[n_train : n_train + n_valid]
test_set  = df_train_source.iloc[n_train + n_valid :]

# 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„' ì»¬ëŸ¼ ì¶”ê°€ (CSV í•˜ë‚˜ë¡œ ê´€ë¦¬í•  ê²½ìš° í¸ë¦¬í•¨)
df_final['ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Prediction' # ê¸°ë³¸ê°’
df_final.loc[train_set.index, 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Train'
df_final.loc[valid_set.index, 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Valid'
df_final.loc[test_set.index,  'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Test'

print(f"        [Split ê²°ê³¼]")
print(f"   - Train (70%) : {len(train_set)}ê±´")
print(f"   - Valid (20%) : {len(valid_set)}ê±´")
print(f"   - Test  (10%) : {len(test_set)}ê±´")
print(f"   - Pred  (ìš´ìš©) : {len(df_pred_source)}ê±´")
# ---------------------------------------------------------
# 3. ì €ì¥ ë° ìš”ì•½
# ---------------------------------------------------------
# ì •ì˜ì„œì— ëª…ì‹œëœ ì¹¼ëŸ¼ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ëˆ„ë½ ë°©ì§€)
output_cols = [
    'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'G2Bëª©ë¡ëª…', 'ë¬¼í’ˆë¶„ë¥˜ëª…', 'ë‚´ìš©ì—°ìˆ˜', 'ì·¨ë“ê¸ˆì•¡', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 
    'ì·¨ë“ì¼ì', 'ë°˜ë‚©ì¼ì', 'ë¶ˆìš©ì¼ì', 'ìƒíƒœë³€í™”', 'ë¶ˆìš©ì‚¬ìœ ', 'ë¬¼í’ˆìƒíƒœ', 
    'ì²˜ë¶„ë°©ì‹', 'ìš´ìš©ë¶€ì„œëª…', 'ìº í¼ìŠ¤', 'ì„œë¹„ìŠ¤ê³„ìˆ˜',
    'ìš´ìš©ì—°ì°¨', 'í•™ìŠµë°ì´í„°ì—¬ë¶€', 'ì”ì—¬ë‚´ìš©ì—°ìˆ˜', 'ë¶€ì„œê°€í˜¹ë„', 'ëˆ„ì ì‚¬ìš©ë¶€í•˜', 
    'ê³ ì¥ì„ë°•ë„', 'ê°€ê²©ë¯¼ê°ë„', 'ì¥ë¹„ì¤‘ìš”ë„', 'ë¦¬ë“œíƒ€ì„ë“±ê¸‰',
    'ì‹¤ì œì”ì—¬ìˆ˜ëª…', 'ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…', '(ì›”ë³„)ê³ ì¥ì˜ˆìƒìˆ˜ëŸ‰', 'ì•ˆì „ì¬ê³ ', 'í•„ìš”ìˆ˜ëŸ‰', 
    'AIì˜ˆì¸¡ê³ ì¥ì¼', 'ì•ˆì „ë²„í¼', 'ê¶Œì¥ë°œì£¼ì¼', 'ì˜ˆì¸¡ì‹¤í–‰ì¼ì'
]

# ì¹¼ëŸ¼ í•„í„°ë§
df_export = df_final[output_cols]

save_path = os.path.join(SAVE_DIR, 'phase4_training_data.csv')
df_export.to_csv(save_path, index=False, encoding='utf-8-sig')

print("-" * 50)
print(f"âœ… ì²˜ë¶„ ì™„ë£Œ(í•™ìŠµìš©) ë°ì´í„°: {len(df_export[df_export['í•™ìŠµë°ì´í„°ì—¬ë¶€']=='Y'])} ê±´")
print(f"âœ… ìš´ìš© ì¤‘(ì˜ˆì¸¡ìš©) ë°ì´í„° : {len(df_export[df_export['í•™ìŠµë°ì´í„°ì—¬ë¶€']=='N'])} ê±´")
print(f"ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_path}")
print("-" * 50)