import pandas as pd
import numpy as np
import os
from datetime import datetime
from pandas.errors import EmptyDataError

# ---------------------------------------------------------
# 0. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOAD_DIR = os.path.join(BASE_DIR, "data_lifecycle")
SAVE_DIR = os.path.join(BASE_DIR, "data_ml")
os.makedirs(SAVE_DIR, exist_ok=True)

print("ğŸ“‚ [Phase 4] AI í•™ìŠµìš© ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")

# [Copilot Fix] ë³‘í•© ì‹œ í•„ìš”í•œ ì»¬ëŸ¼ ì •ì˜ (íŒŒì¼ ëˆ„ë½ ì‹œ KeyError ë°©ì§€ìš©)
COLS_RT = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë°˜ë‚©ì¼ì', 'ë°˜ë‚©í™•ì •ì¼ì', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']
COLS_DU = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë¶ˆìš©ì¼ì', 'ë¶ˆìš©í™•ì •ì¼ì', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']
COLS_DP = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì²˜ë¶„ë°©ì‹', 'ì²˜ë¶„í™•ì •ì¼ì', 'ë¬¼í’ˆìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ']

# [Copilot Fix] ì•ˆì „í•œ íŒŒì¼ ë¡œë”© í•¨ìˆ˜ ì •ì˜ (expected_cols ì¶”ê°€)
def load_csv_safe(filename, required=False, expected_cols=None):
    filepath = os.path.join(LOAD_DIR, filename)
    if os.path.exists(filepath):
        try:
            return pd.read_csv(filepath)
        except EmptyDataError:
            # íŒŒì¼ì€ ìˆì§€ë§Œ ë¹„ì–´ìˆëŠ” ê²½ìš°
            if expected_cols:
                return pd.DataFrame(columns=expected_cols)
            return pd.DataFrame()
    else:
        if required:
            print(f"âŒ í•„ìˆ˜ ë°ì´í„° íŒŒì¼ ëˆ„ë½: {filename}")
            exit()
        else:
            print(f"   âš ï¸ íŒŒì¼ ì—†ìŒ (ë¹ˆ DataFrame ìƒì„±): {filename}")
            if expected_cols:
                return pd.DataFrame(columns=expected_cols)
            return pd.DataFrame()

# 1. ë°ì´í„° ë¡œë“œ (ëª¨ë“  ìƒì• ì£¼ê¸° ë°ì´í„°)
df_op = load_csv_safe('04_01_operation_master.csv', required=True) # ìš´ìš© (í•„ìˆ˜)
df_rt = load_csv_safe('04_03_return_list.csv', expected_cols=COLS_RT)      # ë°˜ë‚©
df_du = load_csv_safe('05_01_disuse_list.csv', expected_cols=COLS_DU)      # ë¶ˆìš©
df_dp = load_csv_safe('06_01_disposal_list.csv', expected_cols=COLS_DP)    # ì²˜ë¶„

print(f"   - ì›ì²œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ìš´ìš© ëŒ€ì¥ {len(df_op)}ê±´")

# ---------------------------------------------------------
# 1. ë°ì´í„° ë³‘í•© (Master Table ìƒì„±)
# ---------------------------------------------------------
print("   1. ìƒì• ì£¼ê¸° ë³‘í•© (ìš´ìš©+ë°˜ë‚©+ë¶ˆìš©+ì²˜ë¶„)...")

# (1) ìš´ìš© + ë°˜ë‚© (Left Join)
# [Copilot Fix] í™•ì •ì¼ì/ìŠ¹ì¸ìƒíƒœ í¬í•¨ ë° ì»¬ëŸ¼ëª… ì¶©ëŒ ë°©ì§€
df_rt_subset = df_rt[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë°˜ë‚©ì¼ì', 'ë°˜ë‚©í™•ì •ì¼ì', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']].rename(
    columns={'ìŠ¹ì¸ìƒíƒœ': 'ë°˜ë‚©ìŠ¹ì¸ìƒíƒœ'}
)
df_merged = pd.merge(df_op, df_rt_subset, on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
df_merged.rename(columns={'ì‚¬ìœ ': 'ìƒíƒœë³€í™”'}, inplace=True) 

# (2) + ë¶ˆìš© (Left Join)
df_du_subset = df_du[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë¶ˆìš©ì¼ì', 'ë¶ˆìš©í™•ì •ì¼ì', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']].rename(
    columns={'ì‚¬ìœ ': 'ë¶ˆìš©ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ': 'ë¶ˆìš©ìŠ¹ì¸ìƒíƒœ'}
)
df_merged = pd.merge(df_merged, df_du_subset, on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

# (3) + ì²˜ë¶„ (Left Join)
df_dp_subset = df_dp[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì²˜ë¶„ë°©ì‹', 'ì²˜ë¶„í™•ì •ì¼ì', 'ë¬¼í’ˆìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ']].rename(
    columns={'ìŠ¹ì¸ìƒíƒœ': 'ì²˜ë¶„ìŠ¹ì¸ìƒíƒœ'}
)
df_merged = pd.merge(df_merged, df_dp_subset, on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
# ---------------------------------------------------------
# 2. ì „ì²˜ë¦¬ ë° ê²°ì¸¡ì¹˜ ë³´ì • (Imputation)
# ---------------------------------------------------------
print("   2. ê²°ì¸¡ì¹˜ ë³´ì • ë° ê¸°ë³¸ í•„ë“œ ì •ë¦¬...")

# [ìˆ˜ì • 2] ë‚ ì§œ ì²˜ë¦¬, ìµœì¢…ì¢…ë£Œì¼ ë° ê¸°ì¤€ì¼ ì„¤ì •
# 1. í˜„ì¬ ì‹œì  ì •ì˜ (Today)
today = pd.to_datetime(datetime.now().date())

# 2. ê¸°ë³¸ ë‚ ì§œ ì»¬ëŸ¼ í˜•ë³€í™˜
date_cols = ['ì·¨ë“ì¼ì', 'ë°˜ë‚©ì¼ì', 'ë¶ˆìš©ì¼ì']
for col in date_cols:
    if col in df_merged.columns:
        df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')

# 3. í™•ì •ì¼ì í˜•ë³€í™˜ (ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
confirm_cols = ['ë°˜ë‚©í™•ì •ì¼ì', 'ë¶ˆìš©í™•ì •ì¼ì', 'ì²˜ë¶„í™•ì •ì¼ì']
for col in confirm_cols:
    if col in df_merged.columns:
        df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')

# 4. í™•ì •ì¼ì ìš°ì„ ìˆœìœ„ ë¡œì§ ì ìš©
# (ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ NaT Series ìƒì„±í•˜ì—¬ ì—ëŸ¬ ë°©ì§€)
_ret_conf = df_merged['ë°˜ë‚©í™•ì •ì¼ì'] if 'ë°˜ë‚©í™•ì •ì¼ì' in df_merged.columns else pd.Series(pd.NaT, index=df_merged.index)
_disuse_conf = df_merged['ë¶ˆìš©í™•ì •ì¼ì'] if 'ë¶ˆìš©í™•ì •ì¼ì' in df_merged.columns else pd.Series(pd.NaT, index=df_merged.index)
_disp_conf = df_merged['ì²˜ë¶„í™•ì •ì¼ì'] if 'ì²˜ë¶„í™•ì •ì¼ì' in df_merged.columns else pd.Series(pd.NaT, index=df_merged.index)

# ìš°ì„ ìˆœìœ„: ì²˜ë¶„í™•ì • > ë¶ˆìš©í™•ì • > ë°˜ë‚©í™•ì • (ê°€ì¥ ëŠ¦ì€ ë‹¨ê³„ì˜ í™•ì •ì¼ì´ ì‹¤ì œ ì¢…ë£Œ ì‹œì )
confirmed_end_date = _disp_conf.combine_first(_disuse_conf).combine_first(_ret_conf)

# -------------------------------------------------------------------------
# [Review Fix] ì°¨ì„ ì±…: ì‹ ì²­ì¼ì (ë°˜ë‚©ì¼ì > ë¶ˆìš©ì¼ì)
# * ìˆ˜ì • ë‚´ìš©: ë‹¨ìˆœíˆ ë‚ ì§œê°€ ìˆë‹¤ê³  ì“°ëŠ” ê²Œ ì•„ë‹ˆë¼, ìŠ¹ì¸ìƒíƒœê°€ 'í™•ì •'ì¸ ê²½ìš°ë§Œ ìœ íš¨í•œ ì¢…ë£Œì¼ë¡œ ì¸ì •
#              (ëŒ€ê¸°/ë°˜ë ¤ ìƒíƒœì¸ ê²½ìš° ìš´ìš© ì¤‘ì¸ ê²ƒìœ¼ë¡œ ê°„ì£¼í•˜ê¸° ìœ„í•¨)
# -------------------------------------------------------------------------
# ë°˜ë‚©ì¼ì ìœ íš¨ì„± ì²´í¬: ë°˜ë‚©ìŠ¹ì¸ìƒíƒœê°€ 'í™•ì •'ì¸ ê²½ìš°ì—ë§Œ ë‚ ì§œ ì±„íƒ
valid_ret_date = df_merged['ë°˜ë‚©ì¼ì'].where(df_merged['ë°˜ë‚©ìŠ¹ì¸ìƒíƒœ'] == 'í™•ì •')

# ë¶ˆìš©ì¼ì ìœ íš¨ì„± ì²´í¬: ë¶ˆìš©ìŠ¹ì¸ìƒíƒœê°€ 'í™•ì •'ì¸ ê²½ìš°ì—ë§Œ ë‚ ì§œ ì±„íƒ
valid_disuse_date = df_merged['ë¶ˆìš©ì¼ì'].where(df_merged['ë¶ˆìš©ìŠ¹ì¸ìƒíƒœ'] == 'í™•ì •')

# Fallback êµ¬ì„±: í™•ì •ëœ ë°˜ë‚©ì¼ì ìš°ì„ , ì—†ìœ¼ë©´ í™•ì •ëœ ë¶ˆìš©ì¼ì
fallback_end_date = valid_ret_date.combine_first(valid_disuse_date)

# ìµœì¢… ì¢…ë£Œì¼ ë„ì¶œ: í™•ì •ì¼ì ìš°ì„  ì ìš©, ì—†ìœ¼ë©´ ì‹ ì²­ì¼ì ì ìš©
df_merged['ìµœì¢…ì¢…ë£Œì¼'] = confirmed_end_date.combine_first(fallback_end_date)

# 5. [ì¤‘ìš”] 'ê¸°ì¤€ì¼' ì»¬ëŸ¼ ìƒì„± (ì¢…ë£Œì¼ì´ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€)
# ì´ ì»¬ëŸ¼ì´ ìƒì„±ë˜ì–´ì•¼ ë’¤ìª½ì˜ íŒŒìƒë³€ìˆ˜(ìš´ìš©ì—°ì°¨ ë“±) ê³„ì‚°ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
df_merged['ê¸°ì¤€ì¼'] = df_merged['ìµœì¢…ì¢…ë£Œì¼'].fillna(today)

# [DataFrame ì´ˆê¸°í™”] ì •ì˜ì„œ ìˆœì„œëŒ€ë¡œ ë°ì´í„° êµ¬ì„±
df_final = pd.DataFrame()

# --- A. ì •ì  ì •ë³´ ë§¤í•‘ ---
df_final['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'] = df_merged['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸']
df_final['G2Bëª©ë¡ëª…'] = df_merged['G2B_ëª©ë¡ëª…']
df_final['ë¬¼í’ˆë¶„ë¥˜ëª…'] = df_merged.get('ë¬¼í’ˆë¶„ë¥˜ëª…', df_merged['G2B_ëª©ë¡ëª…'])
df_final['ë‚´ìš©ì—°ìˆ˜'] = df_merged['ë‚´ìš©ì—°ìˆ˜']
df_final['ì·¨ë“ê¸ˆì•¡'] = df_merged['ì·¨ë“ê¸ˆì•¡']
df_final['ìš´ìš©ë¶€ì„œì½”ë“œ'] = df_merged['ìš´ìš©ë¶€ì„œì½”ë“œ']
df_final['ì·¨ë“ì¼ì'] = df_merged['ì·¨ë“ì¼ì']
df_final['ë°˜ë‚©ì¼ì'] = df_merged['ë°˜ë‚©ì¼ì']
df_final['ë¶ˆìš©ì¼ì'] = df_merged['ë¶ˆìš©ì¼ì']
df_final['ìƒíƒœë³€í™”'] = df_merged['ìƒíƒœë³€í™”']
df_final['ë¶ˆìš©ì‚¬ìœ '] = df_merged['ë¶ˆìš©ì‚¬ìœ ']
df_final['ë¬¼í’ˆìƒíƒœ'] = df_merged['ë¬¼í’ˆìƒíƒœ']
df_final['ì²˜ë¶„ë°©ì‹'] = df_merged['ì²˜ë¶„ë°©ì‹']
# [Copilot Fix] í•™ìŠµì—¬ë¶€ íŒë‹¨ì„ ìœ„í•´ ë³‘í•©ëœ ìŠ¹ì¸ìƒíƒœ/í™•ì •ì¼ì ì •ë³´ë¥¼ ì„ì‹œë¡œ ë§¤í•‘
df_final['ì²˜ë¶„ìŠ¹ì¸ìƒíƒœ'] = df_merged['ì²˜ë¶„ìŠ¹ì¸ìƒíƒœ']
df_final['ì²˜ë¶„í™•ì •ì¼ì'] = df_merged['ì²˜ë¶„í™•ì •ì¼ì']
df_final['ìš´ìš©ë¶€ì„œëª…'] = df_merged['ìš´ìš©ë¶€ì„œ']
df_final['ìº í¼ìŠ¤'] = df_merged['ìº í¼ìŠ¤']
df_final['ê¸°ì¤€ì¼'] = df_merged['ê¸°ì¤€ì¼'] # ê³„ì‚°ìš© ì„ì‹œ ì»¬ëŸ¼

# --- B. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (Imputation) ---
# [Copilot Fix] Feature Engineering ì „ì— ê²°ì¸¡ì¹˜ë¥¼ ë¨¼ì € ì±„ì›€ + ì•ˆì „ì¥ì¹˜ ì¶”ê°€

# 1) ì·¨ë“ê¸ˆì•¡ ê²°ì¸¡/0ì›: ì¤‘ì•™ê°’(Median) ëŒ€ì²´
# ì•ˆì „ì¥ì¹˜: ë°ì´í„°ê°€ ì•„ì˜ˆ ì—†ê±°ë‚˜ ì–‘ìˆ˜ ê¸ˆì•¡ì´ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„
valid_prices = df_final[df_final['ì·¨ë“ê¸ˆì•¡'] > 0]['ì·¨ë“ê¸ˆì•¡']
if not valid_prices.empty:
    median_price = valid_prices.median()
else:
    median_price = 1000000 # Default fallback (100ë§Œì›)

df_final['ì·¨ë“ê¸ˆì•¡'] = df_final['ì·¨ë“ê¸ˆì•¡'].fillna(median_price).replace(0, median_price)

# 2) ë‚´ìš©ì—°ìˆ˜ ê²°ì¸¡: ìµœë¹ˆê°’(Mode) ëŒ€ì²´
# ì•ˆì „ì¥ì¹˜: mode()ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ëŒ€ë¹„
if not df_final['ë‚´ìš©ì—°ìˆ˜'].dropna().empty:
    mode_life = df_final['ë‚´ìš©ì—°ìˆ˜'].mode()[0]
    df_final['ë‚´ìš©ì—°ìˆ˜'] = df_final['ë‚´ìš©ì—°ìˆ˜'].fillna(mode_life)
else:
    df_final['ë‚´ìš©ì—°ìˆ˜'] = df_final['ë‚´ìš©ì—°ìˆ˜'].fillna(5) # Default fallback (5ë…„)

# 3) í•µì‹¬ ë‚ ì§œ(ì·¨ë“ì¼ì) NaT: ì‚­ì œ (ìƒì• ì£¼ê¸° ê³„ì‚° ë¶ˆê°€)
initial_len = len(df_final)
df_final = df_final.dropna(subset=['ì·¨ë“ì¼ì'])
if initial_len != len(df_final):
    print(f"    - ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ì·¨ë“ì¼ì ëˆ„ë½ {initial_len - len(df_final)}ê±´ ì‚­ì œë¨")

# ---------------------------------------------------------
# 3. íŒŒìƒ ë³€ìˆ˜ ìƒì„± (Feature Engineering) - [ë³´ì •ëœ ê°’ ì‚¬ìš©]
# ---------------------------------------------------------
print("   3. íŒŒìƒë³€ìˆ˜ ìƒì„± (ë³´ì •ëœ ë°ì´í„° ê¸°ë°˜)...")

# (1) ìš´ìš©ì—°ì°¨ (Years Used) & ìš´ìš©ì›”ìˆ˜
days_diff = (df_final['ê¸°ì¤€ì¼'] - df_final['ì·¨ë“ì¼ì']).dt.days
# ìŒìˆ˜ ì¼ìˆ˜(ë¯¸ë˜ ì·¨ë“ì¼ì/ê¸°ì¤€ì¼ ì—­ì „ ë“±) ë³´ì •: 0 ë¯¸ë§Œì€ 0ìœ¼ë¡œ clip
days_diff_clipped = days_diff.clip(lower=0)
df_final['ìš´ìš©ì—°ì°¨'] = (days_diff_clipped / 365.0).round(2)
# ìš´ìš©ì—°ì°¨ëŠ” ìŒìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ 0 ë¯¸ë§Œì„ 0ìœ¼ë¡œ ë³´ì • (clipê³¼ ë¡œì§ ì¼ê´€ì„± ìœ ì§€)
df_final['ìš´ìš©ì—°ì°¨'] = df_final['ìš´ìš©ì—°ì°¨'].apply(lambda x: x if x > 0 else 0.0)
df_final['ìš´ìš©ì›”ìˆ˜'] = (days_diff_clipped / 30.0).fillna(0).astype(int)
# (2) ì·¨ë“ì›” (ê³„ì ˆì„±)
df_final['ì·¨ë“ì›”'] = df_final['ì·¨ë“ì¼ì'].dt.month

# (3) í•™ìŠµë°ì´í„°ì—¬ë¶€
# ê¸°ê³„ì  ìˆ˜ëª…ì´ ë‹¤í•œ ê²ƒë§Œ í•™ìŠµ('Y'). ë‹¨ìˆœ ë§¤ê°ì´ë‚˜ í˜„ì¬ ìš´ìš© ì¤‘ì¸ ê²ƒì€ ì˜ˆì¸¡ ëŒ€ìƒ('N')
# [Copilot Fix] ì²˜ë¶„ë°©ì‹ì´ íê¸°/ë©¸ì‹¤ì´ë©´ì„œ, ì‹¤ì œë¡œ 'í™•ì •'ëœ ê±´ë§Œ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©
is_mech_end = df_final['ì²˜ë¶„ë°©ì‹'].isin(['íê¸°', 'ë©¸ì‹¤'])
is_disposal_confirmed = (df_final['ì²˜ë¶„ìŠ¹ì¸ìƒíƒœ'] == 'í™•ì •') | df_final['ì²˜ë¶„í™•ì •ì¼ì'].notna()

df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] = np.where(is_mech_end & is_disposal_confirmed, 'Y', 'N')

# í•™ìŠµì—¬ë¶€ íŒë‹¨ í›„ ì„ì‹œ ì»¬ëŸ¼ ì œê±° (ì„ íƒ ì‚¬í•­, ì €ì¥ ì‹œ ì œì™¸í•´ë„ ë¨)
df_final.drop(columns=['ì²˜ë¶„ìŠ¹ì¸ìƒíƒœ', 'ì²˜ë¶„í™•ì •ì¼ì'], inplace=True)

# (4) ì”ì—¬ë‚´ìš©ì—°ìˆ˜ (ë³´ì •ëœ ë‚´ìš©ì—°ìˆ˜ ì‚¬ìš©)
df_final['ì”ì—¬ë‚´ìš©ì—°ìˆ˜'] = (df_final['ë‚´ìš©ì—°ìˆ˜'] - df_final['ìš´ìš©ì—°ì°¨']).round(2)

# (5) ë¶€ì„œê°€í˜¹ë„ (Department Severity)
def get_severity(dept_name):
    if pd.isna(dept_name): return 1.0
    dept_str = str(dept_name)
    # ê³ ë¶€í•˜ ë¶€ì„œ
    if any(k in dept_str for k in ['ì†Œí”„íŠ¸ì›¨ì–´', 'ê³µí•™', 'ì „ì‚°', 'AI', 'ì •ë³´', 'ì»´í“¨í„°']):
        return 1.3
    # ì¤‘ë¶€í•˜ ë¶€ì„œ
    if 'ì—°êµ¬' in dept_str or 'ì‹¤í—˜' in dept_str:
        return 1.2
    return 1.0

df_final['ë¶€ì„œê°€í˜¹ë„'] = df_final['ìš´ìš©ë¶€ì„œëª…'].apply(get_severity)

# (6) ëˆ„ì ì‚¬ìš©ë¶€í•˜
df_final['ëˆ„ì ì‚¬ìš©ë¶€í•˜'] = (df_final['ìš´ìš©ì—°ì°¨'] * df_final['ë¶€ì„œê°€í˜¹ë„']).round(2)

# (7) ê³ ì¥ì„ë°•ë„ (Failure Imminence) - [ë³´ì •ëœ ë‚´ìš©ì—°ìˆ˜ ì‚¬ìš©]
ratio = df_final['ìš´ìš©ì—°ì°¨'] / df_final['ë‚´ìš©ì—°ìˆ˜']
df_final['ê³ ì¥ì„ë°•ë„'] = (ratio ** 2).clip(0, 1).round(2)

# (8) ê°€ê²©ë¯¼ê°ë„ - [ë³´ì •ëœ ì·¨ë“ê¸ˆì•¡ ì‚¬ìš©]
log_price = np.log1p(df_final['ì·¨ë“ê¸ˆì•¡'])
max_log_price = np.log1p(100000000) 
df_final['ê°€ê²©ë¯¼ê°ë„'] = (log_price / max_log_price).clip(0, 1).round(2)

# (9) ë¦¬ë“œíƒ€ì„ë“±ê¸‰ - [ë³´ì •ëœ ì·¨ë“ê¸ˆì•¡ ì‚¬ìš©]
def get_lead_time_grade(price):
    if pd.isna(price): return 1 # Default
    if price < 5000000: return 0
    elif price < 30000000: return 1
    else: return 2
df_final['ë¦¬ë“œíƒ€ì„ë“±ê¸‰'] = df_final['ì·¨ë“ê¸ˆì•¡'].apply(get_lead_time_grade)

# (10) ì¥ë¹„ì¤‘ìš”ë„ - [ê³„ì‚°ëœ ë¯¼ê°ë„, ë¦¬ë“œíƒ€ì„ë“±ê¸‰ ì‚¬ìš©]
df_final['ì¥ë¹„ì¤‘ìš”ë„'] = ((df_final['ê°€ê²©ë¯¼ê°ë„'] * 0.7) + ((df_final['ë¦¬ë“œíƒ€ì„ë“±ê¸‰'] * 0.5) * 0.3)).round(2)

# --- C. ì˜ˆì¸¡ê°’/ê²°ê³¼ê°’ (Placeholder) ---
df_final['ì‹¤ì œì”ì—¬ìˆ˜ëª…'] = np.nan 
df_final['ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…'] = np.nan
df_final['(ì›”ë³„)ê³ ì¥ì˜ˆìƒìˆ˜ëŸ‰'] = 0
df_final['ì•ˆì „ì¬ê³ '] = 0
df_final['í•„ìš”ìˆ˜ëŸ‰'] = 0
df_final['AIì˜ˆì¸¡ê³ ì¥ì¼'] = pd.NaT
df_final['ì•ˆì „ë²„í¼'] = 0.0
df_final['ê¶Œì¥ë°œì£¼ì¼'] = pd.NaT
df_final['ì˜ˆì¸¡ì‹¤í–‰ì¼ì'] = today.strftime('%Y-%m-%d')

# ---------------------------------------------------------
# 4. ì´ìƒì¹˜ ì œê±° (Outlier Removal)
# ---------------------------------------------------------
print("   4. ì´ìƒì¹˜ ì œê±° ìˆ˜í–‰...")
before_cnt = len(df_final)

# 1) ë…¼ë¦¬ì  ì´ìƒì¹˜: ìš´ìš©ì—°ì°¨ê°€ ìŒìˆ˜ì¸ ê²½ìš°
df_final = df_final[df_final['ìš´ìš©ì—°ì°¨'] >= 0]

# 2) í†µê³„ì  ì´ìƒì¹˜: ì·¨ë“ê¸ˆì•¡ ìƒìœ„ 0.1% ì œê±° (ì™œê³¡ ë°©ì§€)
if not df_final.empty:
    q999 = df_final['ì·¨ë“ê¸ˆì•¡'].quantile(0.999)
    df_final = df_final[df_final['ì·¨ë“ê¸ˆì•¡'] <= q999]

print(f"    - ì´ìƒì¹˜ ì œê±°: {before_cnt - len(df_final)}ê±´ ì œê±°ë¨")

# ---------------------------------------------------------
# 5. ë°ì´í„° ë¶„í•  (Time Series Split) ë° ì €ì¥
# ---------------------------------------------------------
print("   5. ì‹œê³„ì—´ ê¸°ì¤€ ë°ì´í„° ë¶„í•  (Train/Valid/Test)...")

# í•™ìŠµìš© ë°ì´í„°(Y)ë§Œ ë¶„í•  ëŒ€ìƒ
df_train_source = df_final[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y'].copy()
df_pred_source = df_final[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'N'].copy() 

# ì‹œê°„ ìˆœ ì •ë ¬
df_train_source = df_train_source.sort_values(by='ì·¨ë“ì¼ì')

# ë¶„í•  ì¸ë±ìŠ¤ ê³„ì‚°
n_total = len(df_train_source)
n_train = int(n_total * 0.7)
n_valid = int(n_total * 0.2)
n_test = n_total - n_train - n_valid

# ë°ì´í„° ìŠ¬ë¼ì´ì‹±
train_set = df_train_source.iloc[:n_train]
valid_set = df_train_source.iloc[n_train : n_train + n_valid]
test_set  = df_train_source.iloc[n_train + n_valid :]

# 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„' ì»¬ëŸ¼ ì¶”ê°€
df_final['ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Prediction'
df_final.loc[train_set.index, 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Train'
df_final.loc[valid_set.index, 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Valid'
df_final.loc[test_set.index,  'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Test'

print(f"        [Split ê²°ê³¼]")
print(f"   - Train (70%) : {len(train_set)}ê±´")
print(f"   - Valid (20%) : {len(valid_set)}ê±´")
print(f"   - Test  (10%) : {len(test_set)}ê±´")
print(f"   - Pred  (ìš´ìš©) : {len(df_pred_source)}ê±´")

# ìµœì¢… ì €ì¥
output_cols = [
    'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'G2Bëª©ë¡ëª…', 'ë¬¼í’ˆë¶„ë¥˜ëª…', 'ë‚´ìš©ì—°ìˆ˜', 'ì·¨ë“ê¸ˆì•¡', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 
    'ì·¨ë“ì¼ì', 'ë°˜ë‚©ì¼ì', 'ë¶ˆìš©ì¼ì', 'ìƒíƒœë³€í™”', 'ë¶ˆìš©ì‚¬ìœ ', 'ë¬¼í’ˆìƒíƒœ', 
    'ì²˜ë¶„ë°©ì‹', 'ìš´ìš©ë¶€ì„œëª…', 'ìº í¼ìŠ¤',
    'ìš´ìš©ì—°ì°¨', 'í•™ìŠµë°ì´í„°ì—¬ë¶€', 'ì”ì—¬ë‚´ìš©ì—°ìˆ˜', 'ë¶€ì„œê°€í˜¹ë„', 'ëˆ„ì ì‚¬ìš©ë¶€í•˜', 
    'ê³ ì¥ì„ë°•ë„', 'ê°€ê²©ë¯¼ê°ë„', 'ì¥ë¹„ì¤‘ìš”ë„', 'ë¦¬ë“œíƒ€ì„ë“±ê¸‰',
    'ì‹¤ì œì”ì—¬ìˆ˜ëª…', 'ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…', '(ì›”ë³„)ê³ ì¥ì˜ˆìƒìˆ˜ëŸ‰', 'ì•ˆì „ì¬ê³ ', 'í•„ìš”ìˆ˜ëŸ‰', 
    'AIì˜ˆì¸¡ê³ ì¥ì¼', 'ì•ˆì „ë²„í¼', 'ê¶Œì¥ë°œì£¼ì¼', 'ì˜ˆì¸¡ì‹¤í–‰ì¼ì', 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„', 'ìš´ìš©ì›”ìˆ˜', 'ì·¨ë“ì›”'
]

df_export = df_final.reindex(columns=output_cols)
save_path = os.path.join(SAVE_DIR, 'phase4_training_data.csv')
df_export.to_csv(save_path, index=False, encoding='utf-8-sig')

print("-" * 50)
print(f"âœ… ì²˜ë¶„ ì™„ë£Œ(í•™ìŠµìš©) ë°ì´í„°: {len(df_export[df_export['í•™ìŠµë°ì´í„°ì—¬ë¶€']=='Y'])} ê±´")
print(f"âœ… ìš´ìš© ì¤‘(ì˜ˆì¸¡ìš©) ë°ì´í„° : {len(df_export[df_export['í•™ìŠµë°ì´í„°ì—¬ë¶€']=='N'])} ê±´")
print(f"ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_path}")
print("-" * 50)