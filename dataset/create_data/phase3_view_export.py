import pandas as pd
import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOAD_DIR = os.path.join(BASE_DIR, "data_lifecycle") # ì›ì²œ ë°ì´í„°
SAVE_DIR = os.path.join(BASE_DIR, "data_view")      # ë·° ë°ì´í„° (create_data/data_view)
os.makedirs(SAVE_DIR, exist_ok=True) # data_view í´ë” ìƒì„±

# í˜„ì¬ ìœ íš¨í•œ ìƒíƒœë¥¼ ì˜ë¯¸í•˜ëŠ” ì¢…ë£Œì¼ (ë¬´ê¸°í•œ ìœ íš¨)
CURRENT_STATUS_END_DATE = pd.Timestamp('2099-12-31')

# ---------------------------------------------------------
# 0. ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
print("ğŸ“‚ [Phase 3] ì›ì²œ ë°ì´í„° ë¡œë“œ ì¤‘...")

try:
    # Phase 2 ê²°ê³¼ë¬¼
    df_op = pd.read_csv(os.path.join(LOAD_DIR, '04_01_operation_master.csv'))
    df_rt = pd.read_csv(os.path.join(LOAD_DIR, '04_03_return_list.csv'))
    df_du = pd.read_csv(os.path.join(LOAD_DIR, '05_01_disuse_list.csv'))
    df_dp = pd.read_csv(os.path.join(LOAD_DIR, '06_01_disposal_list.csv'))
    df_hist = pd.read_csv(os.path.join(LOAD_DIR, '99_asset_status_history.csv'))

    # ë°ì´í„° í”„ë ˆì„ ì „ì²´ì˜ NaN(ê²°ì¸¡ì¹˜)ë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì¹˜í™˜ (ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ)
    # ë‚ ì§œë‚˜ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ë‘ì–´ì•¼ ì˜¤ë¥˜ê°€ ì•ˆ ë‚¨
    str_cols = ['ë¹„ê³ ', 'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ', 'ì‚¬ìœ ', 'ë¬¼í’ˆìƒíƒœ']
    
    for df in [df_op, df_rt, df_du, df_dp]:
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].fillna('')

except FileNotFoundError as e:
    print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Phase 1, 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”. ({e})")
    exit()
except Exception as e:
    print(f"âŒ CSV ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    exit()

# ---------------------------------------------------------
# 1. í™”ë©´ë³„ View CSV ìƒì„±
# ---------------------------------------------------------
print("âš™ï¸ [Phase 3] í™”ë©´ë³„ ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ View CSV ìƒì„± ì¤‘...")

# [04-01] ë¬¼í’ˆ ìš´ìš© - ë¬¼í’ˆê¸°ë³¸ì •ë³´ (Grouped View)
print("   - [04-01] ìš´ìš© í™”ë©´ìš© ê¸°ë³¸ì •ë³´ ì§‘ê³„ ì¤‘...")

group_cols_op = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ìº í¼ìŠ¤','ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
]

# ë°ì´í„° ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
if set(group_cols_op).issubset(df_op.columns):
    view_op_basic = df_op.groupby(group_cols_op).size().reset_index(name='ìˆ˜ëŸ‰')
    view_op_basic.to_csv(os.path.join(SAVE_DIR, 'View_04_01_ìš´ìš©_ê¸°ë³¸ì •ë³´.csv'), index=False, encoding='utf-8-sig')
else:
    print("   âš ï¸ ê²½ê³ : 04_01 íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# [06-01] ë¬¼í’ˆ ë¶ˆìš©/ì²˜ë¶„ ê´€ë¦¬ (View ìƒì„± ì‹œ ì•ˆì „ì„± ë³´ê°•)
# Phase 2ì—ì„œ ë¦¬ìŠ¤íŠ¸ì— 'ë‚´ìš©ì—°ìˆ˜' ë“±ì„ ì•ˆ ë„£ì—ˆì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ, df_opì™€ ë³‘í•©í•˜ì—¬ ì •ë³´ ì±„ì›€
print("   - [06-01] ë¶ˆìš© ë¬¼í’ˆ ëª©ë¡ ìƒì„± ì¤‘ (Master ì •ë³´ ë³‘í•©)...")

# ë³‘í•©ì— ì‚¬ìš©í•  Master ì •ë³´ (ë³€í•˜ì§€ ì•ŠëŠ” ì†ì„±)
master_cols = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë‚´ìš©ì—°ìˆ˜', 'ì·¨ë“ê¸ˆì•¡', 'ì·¨ë“ì¼ì', 'ì •ë¦¬ì¼ì', 'G2B_ëª©ë¡ëª…']
df_master_info = df_op[master_cols].drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'])

# ë¶ˆìš© ëª©ë¡ì— Master ì •ë³´ ë³‘í•© (Suffix ë°©ì§€ ìœ„í•´ ì»¬ëŸ¼ í™•ì¸)
# df_duì— ì´ë¯¸ ìˆëŠ” ì»¬ëŸ¼ì€ ì œì™¸í•˜ê³  ë³‘í•©
cols_to_merge = [c for c in master_cols if c not in df_du.columns or c == 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸']
view_du_item = pd.merge(df_du, df_master_info[cols_to_merge], on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
target_cols_du = ['G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 'ë¶ˆìš©ì¼ì','ë¬¼í’ˆìƒíƒœ','ë‚´ìš©ì—°ìˆ˜']
# ë§Œì•½ ì—¬ì „íˆ ì—†ëŠ” ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì—ëŸ¬ ë°©ì§€
valid_cols_du = [c for c in target_cols_du if c in view_du_item.columns]
view_du_item = view_du_item[valid_cols_du]

view_du_item.to_csv(os.path.join(SAVE_DIR, 'View_06_01_ë¶ˆìš©ë¬¼í’ˆëª©ë¡.csv'), index=False, encoding='utf-8-sig')


# [07-01] ë³´ìœ  í˜„í™© ì¡°íšŒ (SCD Type 2 History)
print("   - [07-01] ë³´ìœ  í˜„í™©(ê³¼ê±° ì‹œì  ì¡°íšŒìš©) ë°ì´í„° ìƒì„± ì¤‘...")

# 1. ì´ë ¥ ë°ì´í„° ì •ë ¬
df_hist['ë³€ê²½ì¼ì'] = pd.to_datetime(df_hist['ë³€ê²½ì¼ì'])
df_hist = df_hist.sort_values(by=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë³€ê²½ì¼ì'])

# 2. ìœ íš¨ ê¸°ê°„(Start ~ End) ìƒì„±
df_hist['ìœ íš¨ì‹œì‘ì¼ì'] = df_hist['ë³€ê²½ì¼ì']
df_hist['ìœ íš¨ì¢…ë£Œì¼ì'] = df_hist.groupby('ë¬¼í’ˆê³ ìœ ë²ˆí˜¸')['ë³€ê²½ì¼ì'].shift(-1) - pd.Timedelta(days=1)
df_hist['ìœ íš¨ì¢…ë£Œì¼ì'] = df_hist['ìœ íš¨ì¢…ë£Œì¼ì'].fillna(CURRENT_STATUS_END_DATE)

# 3. ì†ì„± ì •ë³´ ê²°í•©
# [ìˆ˜ì •] ì •ì  ì •ë³´ëŠ” df_opì—ì„œ ê°€ì ¸ì˜¤ë˜, ë¶€ì„œ ì •ë³´ëŠ” df_acqì—ì„œ ê°€ì ¸ì˜´ (ë°˜ë‚© ì‹œ ë¶€ì„œê°€ ì‚¬ë¼ì§€ë¯€ë¡œ)
static_cols = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìº í¼ìŠ¤', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 'ì·¨ë“ì •ë¦¬êµ¬ë¶„','ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
]
df_static = df_op[static_cols].drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'])

# ë³‘í•©
df_scd_raw = pd.merge(df_hist, df_static, on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

# ìš´ìš©ë¶€ì„œ ë¹ˆê°’ ì²˜ë¦¬ (ë¹ˆì¹¸ ê·¸ëŒ€ë¡œ ë‘ê±°ë‚˜ 'ìš´ìš©ë¶€ì„œì—†ìŒ'ìœ¼ë¡œ í‘œì‹œ)
df_scd_raw['ìš´ìš©ë¶€ì„œ'] = df_scd_raw['ìš´ìš©ë¶€ì„œ'].fillna('')

# ìƒíƒœê°’ ë§¤í•‘: ì´ë ¥ ë°ì´í„°ì˜ '(ë³€ê²½)ìš´ìš©ìƒíƒœ'ê°€ ê·¸ ë‹¹ì‹œì˜ ì‹¤ì œ ìƒíƒœ
df_scd_raw['ìš´ìš©ìƒíƒœ'] = df_scd_raw['(ë³€ê²½)ìš´ìš©ìƒíƒœ']

# 4. ê·¸ë£¹í•‘ ë° ìˆ˜ëŸ‰ ì§‘ê³„
group_cols_scd = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ìº í¼ìŠ¤',
    'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ ',
    'ìœ íš¨ì‹œì‘ì¼ì', 'ìœ íš¨ì¢…ë£Œì¼ì'
]

# ë‚ ì§œ í¬ë§·íŒ…
df_scd_raw['ìœ íš¨ì‹œì‘ì¼ì'] = df_scd_raw['ìœ íš¨ì‹œì‘ì¼ì'].dt.strftime('%Y-%m-%d')
df_scd_raw['ìœ íš¨ì¢…ë£Œì¼ì'] = df_scd_raw['ìœ íš¨ì¢…ë£Œì¼ì'].dt.strftime('%Y-%m-%d')
df_scd_raw = df_scd_raw.fillna('')

view_inventory_scd = df_scd_raw.groupby(group_cols_scd).size().reset_index(name='ìˆ˜ëŸ‰')

# 5. ìµœì¢… ì €ì¥
view_inventory_scd.to_csv(os.path.join(SAVE_DIR, 'View_07_01_ë³´ìœ í˜„í™©_ì´ë ¥ê¸°ë°˜.csv'), index=False, encoding='utf-8-sig')

# ---------------------------------------------------------
# 2. ë°ì´í„° ì •í•©ì„± ê²€ì¦ (Validation)
# ---------------------------------------------------------
print("\nğŸ” [Phase 3] ë°ì´í„° ì •í•©ì„± ê²€ì¦ ì‹œì‘")

# ê²€ì¦ 1: ì´ë ¥ ê¸°ë°˜ ë°ì´í„° ê²€ì¦
current_snapshot = view_inventory_scd[view_inventory_scd['ìœ íš¨ì¢…ë£Œì¼ì'] == '2099-12-31']
total_op = len(df_op)
current_snapshot_qty = pd.to_numeric(current_snapshot['ìˆ˜ëŸ‰'], errors='coerce').sum()

print(f"1. ìµœì‹  ìƒíƒœ ë™ê¸°í™” ê²€ì¦: ìš´ìš©ëŒ€ì¥({total_op}) vs ì´ë ¥ìŠ¤ëƒ…ìƒ·({int(current_snapshot_qty)})")
if total_op == current_snapshot_qty:
    print("   âœ… PASS: ì¼ì¹˜í•©ë‹ˆë‹¤.")
else:
    print("   âŒ FAIL: ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œìƒ.")

# ê²€ì¦ 2: ë‚ ì§œ ë…¼ë¦¬ í™•ì¸
print("2. ë‚ ì§œ ë…¼ë¦¬ ê²€ì¦ (ì·¨ë“ì¼ì < ë¶ˆìš©ì¼ì)")
if not df_du.empty:
    # df_duì— ì·¨ë“ì¼ìê°€ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ df_master_infoì™€ ë³‘í•©ëœ view_du_item ì‚¬ìš© ê¶Œì¥
    df_check = view_du_item.copy()
    df_check['ì·¨ë“ì¼ì'] = pd.to_datetime(df_check['ì·¨ë“ì¼ì'], errors='coerce')
    df_check['ë¶ˆìš©ì¼ì'] = pd.to_datetime(df_check['ë¶ˆìš©ì¼ì'], errors='coerce')
    
    error_count = (df_check['ë¶ˆìš©ì¼ì'] < df_check['ì·¨ë“ì¼ì']).sum()
    
    if error_count == 0:
        print("   âœ… PASS: ì‹œê°„ ìˆœì„œ ì •ìƒ.")
    else:
        print(f"   âŒ FAIL: {error_count}ê±´ ì‹œê°„ ì—­ì „.")
else:
    print("   â„¹ï¸ ë¶ˆìš© ë°ì´í„°ê°€ ì—†ì–´ ê²€ì¦ ê±´ë„ˆëœ€.")

print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")