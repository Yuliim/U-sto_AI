import pandas as pd
import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOAD_DIR = os.path.join(BASE_DIR, "data_lifecycle") # ì›ì²œ ë°ì´í„°
SAVE_DIR = os.path.join(BASE_DIR, "data_view")      # ë·° ë°ì´í„° (create_data/data_view)
os.makedirs(SAVE_DIR, exist_ok=True) # data_view í´ë” ìƒì„±

# í˜„ì¬ ìœ íš¨í•œ ìƒíƒœë¥¼ ì˜ë¯¸í•˜ëŠ” ì¢…ë£Œì¼ (ë¬´ê¸°í•œ ìœ íš¨)
CURRENT_STATUS_END_DATE = pd.Timestamp('2099-12-31')

# ---------------------------------------------------------
# 0. ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
print("ğŸ“‚ [Phase 3] ì›ì²œ ë°ì´í„° ë¡œë“œ ì¤‘...")

try:
    # Phase 2 ê²°ê³¼ë¬¼
    df_op = pd.read_csv(os.path.join(LOAD_DIR, '04_01_operation_master.csv'))
    df_rt = pd.read_csv(os.path.join(LOAD_DIR, '04_03_return_list.csv'))
    df_du = pd.read_csv(os.path.join(LOAD_DIR, '05_01_disuse_list.csv'))
    df_dp = pd.read_csv(os.path.join(LOAD_DIR, '06_01_disposal_list.csv'))
    df_hist = pd.read_csv(os.path.join(LOAD_DIR, '99_asset_status_history.csv'))

    # ë¦¬ë·°ì–´ ì§€ì  ì‚¬í•­: ê³¼ê±° ë¶€ì„œ ì •ë³´ ë³µì›ì„ ìœ„í•´ ìš´ìš©ì‹ ì²­ ì´ë ¥ ë¡œë“œ
    path_req = os.path.join(LOAD_DIR, '04_02_operation_req_list.csv')
    if os.path.exists(path_req):
        df_req = pd.read_csv(path_req)
    else:
        df_req = pd.DataFrame(columns=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ì‹ ì²­ì¼ì'])
        
    # ë°ì´í„° í”„ë ˆì„ ì „ì²´ì˜ NaN(ê²°ì¸¡ì¹˜)ë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì¹˜í™˜ (ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ)
    # ë‚ ì§œë‚˜ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ë‘ì–´ì•¼ ì˜¤ë¥˜ê°€ ì•ˆ ë‚¨
    str_cols = ['ë¹„ê³ ', 'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ', 'ì‚¬ìœ ', 'ë¬¼í’ˆìƒíƒœ']
    
    for df in [df_op, df_rt, df_du, df_dp]:
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].fillna('')

except FileNotFoundError as e:
    print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Phase 1, 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”. ({e})")
    exit()
except Exception as e:
    print(f"âŒ CSV ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    exit()

# ---------------------------------------------------------
# 1. í™”ë©´ë³„ View CSV ìƒì„±
# ---------------------------------------------------------
print("âš™ï¸ [Phase 3] í™”ë©´ë³„ ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ View CSV ìƒì„± ì¤‘...")

# [04-01] ë¬¼í’ˆ ìš´ìš© - ë¬¼í’ˆê¸°ë³¸ì •ë³´ (Grouped View)
print("   - [04-01] ìš´ìš© í™”ë©´ìš© ê¸°ë³¸ì •ë³´ ì§‘ê³„ ì¤‘...")

group_cols_op = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ìº í¼ìŠ¤','ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
]

# ë°ì´í„° ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
if set(group_cols_op).issubset(df_op.columns):
    view_op_basic = df_op.groupby(group_cols_op).size().reset_index(name='ìˆ˜ëŸ‰')
    view_op_basic.to_csv(os.path.join(SAVE_DIR, 'View_04_01_ìš´ìš©_ê¸°ë³¸ì •ë³´.csv'), index=False, encoding='utf-8-sig')
else:
    print("   âš ï¸ ê²½ê³ : 04_01 íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# [06-01] ë¶ˆìš© ë¬¼í’ˆ ëª©ë¡
# ë³‘í•©ì— ì‚¬ìš©í•  Master ì •ë³´
master_cols = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë‚´ìš©ì—°ìˆ˜', 'ì·¨ë“ê¸ˆì•¡', 'ì·¨ë“ì¼ì', 'ì •ë¦¬ì¼ì', 'G2B_ëª©ë¡ëª…']
df_master_info = df_op[master_cols].drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'])
cols_to_merge = [c for c in master_cols if c == 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸' or c not in df_du.columns]
view_du_item = pd.merge(df_du, df_master_info[cols_to_merge], on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
view_du_item.to_csv(os.path.join(SAVE_DIR, 'View_06_01_ë¶ˆìš©ë¬¼í’ˆëª©ë¡.csv'), index=False, encoding='utf-8-sig')

# [07-01] ë³´ìœ  í˜„í™© ì¡°íšŒ (SCD Type 2 History)
print("   - [07-01] ë³´ìœ  í˜„í™©(ê³¼ê±° ì‹œì  ì¡°íšŒìš©) ë°ì´í„° ìƒì„± ì¤‘...")

# 1. ì´ë ¥ ë°ì´í„° ì •ë ¬
df_hist['ë³€ê²½ì¼ì'] = pd.to_datetime(df_hist['ë³€ê²½ì¼ì'])
df_hist = df_hist.sort_values(by=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë³€ê²½ì¼ì'])

# 2. ìœ íš¨ ê¸°ê°„(Start ~ End) ìƒì„±
df_hist['ìœ íš¨ì‹œì‘ì¼ì'] = df_hist['ë³€ê²½ì¼ì']
df_hist['ìœ íš¨ì¢…ë£Œì¼ì'] = df_hist.groupby('ë¬¼í’ˆê³ ìœ ë²ˆí˜¸')['ë³€ê²½ì¼ì'].shift(-1) - pd.Timedelta(days=1)
df_hist['ìœ íš¨ì¢…ë£Œì¼ì'] = df_hist['ìœ íš¨ì¢…ë£Œì¼ì'].fillna(CURRENT_STATUS_END_DATE)

# 3. ì†ì„± ì •ë³´ ê²°í•©
# ì •ì  ì •ë³´(ìš´ìš©ë¶€ì„œ í¬í•¨)ëŠ” ëª¨ë‘ df_opì—ì„œ ê°€ì ¸ì˜´
static_cols = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìº í¼ìŠ¤', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 'ì·¨ë“ì •ë¦¬êµ¬ë¶„','ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
]
df_static = df_op[static_cols].drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'])
df_scd_raw = pd.merge(df_hist, df_static, on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

# 3-2. ë¶€ì„œ ì •ë³´ ë³µì› (ë¦¬ë·° ë°˜ì˜)
# ìš´ìš©ëŒ€ì¥ì€ ë°˜ë‚© ì‹œ ë¶€ì„œê°€ ë¹„ì–´ìˆìœ¼ë¯€ë¡œ, df_req(ìš´ìš©ì‹ ì²­)ì—ì„œ ìµœê·¼ ë¶€ì„œë¥¼ ê°€ì ¸ì™€ ì±„ì›€
if not df_req.empty and {'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ì‹ ì²­ì¼ì'}.issubset(df_req.columns):
    dept_map = (
        df_req.sort_values('ìš´ìš©ì‹ ì²­ì¼ì')
        .drop_duplicates('ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', keep='last')[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìš´ìš©ë¶€ì„œ']]
    )

    df_scd_raw = pd.merge(
        df_scd_raw,
        dept_map,
        on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸',
        how='left',
        suffixes=('', '_req')
    )

    # ìš´ìš©ë¶€ì„œ_req ì»¬ëŸ¼ì´ ì¡´ì¬í•  ë•Œë§Œ ë³´ì •
    if 'ìš´ìš©ë¶€ì„œ_req' in df_scd_raw.columns:
        df_scd_raw['ìš´ìš©ë¶€ì„œ'] = (
            df_scd_raw['ìš´ìš©ë¶€ì„œ']
            .replace('', pd.NA)
            .fillna(df_scd_raw['ìš´ìš©ë¶€ì„œ_req'])
            .fillna('')
        )
        df_scd_raw = df_scd_raw.drop(columns=['ìš´ìš©ë¶€ì„œ_req'])


# 4. ìƒíƒœê°’ ë§¤í•‘ ë° í¬ë§·íŒ…
df_scd_raw['ìš´ìš©ìƒíƒœ'] = df_scd_raw['(ë³€ê²½)ìš´ìš©ìƒíƒœ']
df_scd_raw['ìœ íš¨ì‹œì‘ì¼ì'] = df_scd_raw['ìœ íš¨ì‹œì‘ì¼ì'].dt.strftime('%Y-%m-%d')
df_scd_raw['ìœ íš¨ì¢…ë£Œì¼ì'] = df_scd_raw['ìœ íš¨ì¢…ë£Œì¼ì'].dt.strftime('%Y-%m-%d')
df_scd_raw = df_scd_raw.fillna('')

# 5. ê·¸ë£¹í•‘ ë° ìˆ˜ëŸ‰ ì§‘ê³„
group_cols_scd = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ìº í¼ìŠ¤',
    'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ ',
    'ìœ íš¨ì‹œì‘ì¼ì', 'ìœ íš¨ì¢…ë£Œì¼ì'
]
view_inventory_scd = df_scd_raw.groupby(group_cols_scd).size().reset_index(name='ìˆ˜ëŸ‰')
view_inventory_scd.to_csv(os.path.join(SAVE_DIR, 'View_07_01_ë³´ìœ í˜„í™©_ì´ë ¥ê¸°ë°˜.csv'), index=False, encoding='utf-8-sig')

# ---------------------------------------------------------
# 2. ë°ì´í„° ì •í•©ì„± ê²€ì¦ (Validation)
# ---------------------------------------------------------
print("\nğŸ” [Phase 3] ë°ì´í„° ì •í•©ì„± ê²€ì¦ ì‹œì‘")

# ê²€ì¦ 1: ì´ë ¥ ê¸°ë°˜ ë°ì´í„° ê²€ì¦
current_snapshot = view_inventory_scd[
    view_inventory_scd['ìœ íš¨ì¢…ë£Œì¼ì'] == CURRENT_STATUS_END_DATE.strftime('%Y-%m-%d')
]
total_op = len(df_op)
current_snapshot_qty = pd.to_numeric(current_snapshot['ìˆ˜ëŸ‰'], errors='coerce').sum()

print(f"1. ìµœì‹  ìƒíƒœ ë™ê¸°í™” ê²€ì¦: ìš´ìš©ëŒ€ì¥({total_op}) vs ì´ë ¥ìŠ¤ëƒ…ìƒ·({int(current_snapshot_qty)})")
if total_op == current_snapshot_qty:
    print("   âœ… PASS: ì¼ì¹˜í•©ë‹ˆë‹¤.")
else:
    print("   âŒ FAIL: ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œìƒ.")

# ê²€ì¦ 2: ë‚ ì§œ ë…¼ë¦¬ í™•ì¸
if not df_du.empty:
    # df_duì— ì·¨ë“ì¼ìê°€ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ df_master_infoì™€ ë³‘í•©ëœ view_du_item ì‚¬ìš© ê¶Œì¥
    df_check = view_du_item.copy()
    df_check['ì·¨ë“ì¼ì'] = pd.to_datetime(df_check['ì·¨ë“ì¼ì'], errors='coerce')
    df_check['ë¶ˆìš©ì¼ì'] = pd.to_datetime(df_check['ë¶ˆìš©ì¼ì'], errors='coerce')

    # NaT ì—¬ë¶€ ì§‘ê³„
    invalid_mask = df_check['ì·¨ë“ì¼ì'].isna() | df_check['ë¶ˆìš©ì¼ì'].isna()
    invalid_cnt = invalid_mask.sum()

    # ìœ íš¨ ë‚ ì§œë§Œ ë¹„êµ
    valid_df = df_check[~invalid_mask]
    error_cnt = (valid_df['ë¶ˆìš©ì¼ì'] < valid_df['ì·¨ë“ì¼ì']).sum()

    print("2. ë‚ ì§œ ë…¼ë¦¬ ê²€ì¦ (ì·¨ë“ì¼ì < ë¶ˆìš©ì¼ì)")
    if error_cnt == 0:
        print("   âœ… PASS: ì‹œê°„ ìˆœì„œ ì •ìƒ.")
    else:
        print(f"   âŒ FAIL: {error_cnt}ê±´ ì‹œê°„ ì—­ì „.")

    if invalid_cnt > 0:
        print(f"   âš ï¸ ì°¸ê³ : ë‚ ì§œ ëˆ„ë½/í˜•ì‹ ì˜¤ë¥˜ {invalid_cnt}ê±´ ì¡´ì¬.")
else:
    print("   â„¹ï¸ ë¶ˆìš© ë°ì´í„°ê°€ ì—†ì–´ ê²€ì¦ ê±´ë„ˆëœ€.")

# [Fix] ì²˜ë¶„ ìƒíƒœ ë™ê¸°í™” ê²€ì¦ (ìŠ¹ì¸ ìƒíƒœ ê³ ë ¤)
if not df_dp.empty:
    # ì²˜ë¶„ ëª©ë¡ ì¤‘ 'í™•ì •'ì¸ ê±´ë“¤ë§Œ ì¶”ì¶œ
    confirmed_disposal_ids = df_dp[df_dp['ìŠ¹ì¸ìƒíƒœ'] == 'í™•ì •']['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'].unique()
    
    # ìš´ìš©ëŒ€ì¥ì—ì„œ í•´ë‹¹ ID ì¡°íšŒ
    if len(confirmed_disposal_ids) == 0:
        # í™•ì •ëœ ì²˜ë¶„ ê±´ì´ ì—†ëŠ” ê²½ìš°
        print("3. ì²˜ë¶„ ìƒíƒœ(í™•ì •ê±´): â„¹ï¸ í™•ì •ëœ ì²˜ë¶„ ê±´ì´ ì—†ì–´ ê²€ì¦ ê±´ë„ˆëœ€.")
    
    # ìƒíƒœê°€ 'ì²˜ë¶„'ì´ ì•„ë‹Œ ê²ƒ ì¹´ìš´íŠ¸
    else:
        op_status = df_op[df_op['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'].isin(confirmed_disposal_ids)]['ìš´ìš©ìƒíƒœ']
        err_cnt = (op_status != 'ì²˜ë¶„').sum()
        print(f"3. ì²˜ë¶„ ìƒíƒœ(í™•ì •ê±´): {'âœ… PASS' if err_cnt == 0 else f'âŒ FAIL ({err_cnt}ê±´ ë¯¸ë°˜ì˜)'}")
    
    # ëŒ€ê¸°/ë°˜ë ¤ ìƒíƒœì¸ ê±´ìˆ˜ ì¶œë ¥ (ID ê¸°ì¤€ì´ ì•„ë‹Œ Row ê¸°ì¤€ ì§‘ê³„)
    # ê¸°ì¡´: len(df_dp) - len(confirmed_ids) -> ì¤‘ë³µ IDë‚˜ ë¡œì§ ì˜¤ë¥˜ ê°€ëŠ¥ì„± ìˆìŒ
    pending_cnt = (df_dp['ìŠ¹ì¸ìƒíƒœ'] != 'í™•ì •').sum()
    print(f"   (ì°¸ê³ ) ì§„í–‰ ì¤‘ì¸ ì²˜ë¶„ ê±´: {pending_cnt}ê±´")

print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")