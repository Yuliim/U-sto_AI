import pandas as pd
import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOAD_DIR = os.path.join(BASE_DIR, "data_lifecycle") # ì›ì²œ ë°ì´í„°
SAVE_DIR = os.path.join(BASE_DIR, "data_view")      # ë·° ë°ì´í„° (create_data/data_view)
os.makedirs(SAVE_DIR, exist_ok=True) # data_view í´ë” ìƒì„±

# í˜„ì¬ ìœ íš¨í•œ ìƒíƒœë¥¼ ì˜ë¯¸í•˜ëŠ” ì¢…ë£Œì¼ (ë¬´ê¸°í•œ ìœ íš¨)
CURRENT_STATUS_END_DATE = pd.Timestamp('2099-12-31')
# ---------------------------------------------------------
# 0. ë°ì´í„° ë¡œë“œ (Phase 2 ê²°ê³¼ë¬¼)
# ---------------------------------------------------------
print("ğŸ“‚ [Phase 3] ì›ì²œ ë°ì´í„° ë¡œë“œ ì¤‘...")

try:
    df_op = pd.read_csv(os.path.join(LOAD_DIR, '04_01_operation_master.csv'))
    df_rt = pd.read_csv(os.path.join(LOAD_DIR, '04_03_return_list.csv'))
    df_du = pd.read_csv(os.path.join(LOAD_DIR, '05_01_disuse_list.csv'))
    df_dp = pd.read_csv(os.path.join(LOAD_DIR, '06_01_disposal_list.csv'))
    df_hist = pd.read_csv(os.path.join(LOAD_DIR, '99_asset_status_history.csv'))

    # ë°ì´í„° í”„ë ˆì„ ì „ì²´ì˜ NaN(ê²°ì¸¡ì¹˜)ë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì¹˜í™˜
    # groupby ì‹œ NaN ê°’ì„ ê°€ì§„ í–‰ì´ ì œì™¸ë˜ì§€ ì•Šë„ë¡ 'ë¹„ê³ 'ë‚˜ 'ë¶€ì„œ' ë“± ë¹„-ë‚ ì§œ ì»¬ëŸ¼ë§Œ ë¹ˆ ë¬¸ìì—´ë¡œ ì¹˜í™˜
    df_op = df_op.fillna(value={'ë¹„ê³ ': '', 'ìš´ìš©ë¶€ì„œ': ''})
    df_rt = df_rt.fillna(value={'ë¹„ê³ ': '', 'ìš´ìš©ë¶€ì„œ': ''})
    df_du = df_du.fillna(value={'ë¹„ê³ ': '', 'ìš´ìš©ë¶€ì„œ': ''})
    df_dp = df_dp.fillna(value={'ë¹„ê³ ': '', 'ìš´ìš©ë¶€ì„œ': ''})

    # df_histëŠ” ë‚ ì§œ ê³„ì‚°ì´ í•„ìš”í•˜ë¯€ë¡œ ë‚˜ì¤‘ì— ì²˜ë¦¬
except FileNotFoundError as e:
    print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Phase 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”. ({e})")
    exit()
except PermissionError as e:
    print(f"âŒ íŒŒì¼ ì ‘ê·¼ ê¶Œí•œ ì˜¤ë¥˜: {e}")
    exit()
except Exception as e:
    print(f"âŒ CSV ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    exit()
# ---------------------------------------------------------
# 1. í™”ë©´ë³„ View CSV ìƒì„±
# ---------------------------------------------------------
print("âš™ï¸ [Phase 3] í™”ë©´ë³„ ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ View CSV ìƒì„± ì¤‘...")

# [04-01] ë¬¼í’ˆ ìš´ìš© - ë¬¼í’ˆê¸°ë³¸ì •ë³´ (Grouped View)
# ê°œë…: í˜„ì¬ ì‹œì ì˜ ìµœì¢… ìƒíƒœë¥¼ ë³´ì—¬ì¤Œ. (ê³¼ê±° ë‚ ì§œë¡œ í•„í„°ë§í•´ë„ ìƒíƒœëŠ” 'í˜„ì¬' ìƒíƒœ)
print("   - [04-01] ìš´ìš© í™”ë©´ìš© ê¸°ë³¸ì •ë³´ ì§‘ê³„ ì¤‘...")

# ê·¸ë£¹í•‘ ê¸°ì¤€ ì»¬ëŸ¼ (ë¬¼í’ˆê¸°ë³¸ì •ë³´ì— ë“¤ì–´ê°€ëŠ” ì†ì„±ë“¤ ì¤‘ ê³ ìœ ë²ˆí˜¸ ì œì™¸)
group_cols_op = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
]

# ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ í›„ ì§„í–‰
if set(group_cols_op).issubset(df_op.columns):
    # í˜„ì¬ ìƒíƒœ(df_op)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ìˆ˜ëŸ‰ ê³„ì‚°
    view_op_basic = df_op.groupby(group_cols_op).size().reset_index(name='ìˆ˜ëŸ‰')
    # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ 
    final_cols_op = [
        'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
        'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìˆ˜ëŸ‰', 'ìŠ¹ì¸ìƒíƒœ', 
        'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
    ]
    view_op_basic = view_op_basic[final_cols_op]
    view_op_basic.to_csv(os.path.join(SAVE_DIR, 'View_04_01_ìš´ìš©_ê¸°ë³¸ì •ë³´.csv'), index=False, encoding='utf-8-sig')
else:
    print("   âš ï¸ ê²½ê³ : 04_01 íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. Phase 2 ì½”ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# [06-01] ë¬¼í’ˆ ì²˜ë¶„ ê´€ë¦¬
# ë¶ˆìš© ë¬¼í’ˆ ëª©ë¡
view_du_item = df_du[['G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 'ë¶ˆìš©ì¼ì','ë¬¼í’ˆìƒíƒœ','ë‚´ìš©ì—°ìˆ˜']]
view_du_item.to_csv(os.path.join(SAVE_DIR, 'View_06_01_ë¶ˆìš©ë¬¼í’ˆëª©ë¡.csv'), index=False, encoding='utf-8-sig')


# [07-01] ë³´ìœ  í˜„í™© ì¡°íšŒ (Aggregation)
# ê°œë…: "ê·¸ ë‹¹ì‹œ"ì˜ ìˆ˜ëŸ‰ì„ ë³´ì—¬ì¤Œ.
# êµ¬í˜„: (ì†ì„± + ìœ íš¨ê¸°ê°„)ìœ¼ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ìˆ˜ëŸ‰ ì§‘ê³„
print("   - [07-01] ë³´ìœ  í˜„í™©(ê³¼ê±° ì‹œì  ì¡°íšŒìš©) ë°ì´í„° ìƒì„± ì¤‘...")

# 1. ì´ë ¥ ë°ì´í„° ì •ë ¬ (ë¬¼í’ˆë³„, ë‚ ì§œìˆœ)
df_hist['ë³€ê²½ì¼ì'] = pd.to_datetime(df_hist['ë³€ê²½ì¼ì'])
df_hist = df_hist.sort_values(by=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë³€ê²½ì¼ì'])

# 2. ìœ íš¨ ê¸°ê°„(Start ~ End) ìƒì„±
df_hist['ìœ íš¨ì‹œì‘ì¼ì'] = df_hist['ë³€ê²½ì¼ì']
# ë‹¤ìŒ ìƒíƒœë¡œ ë³€í•˜ê¸° ì „ë‚ ì´ ì¢…ë£Œì¼
df_hist['ìœ íš¨ì¢…ë£Œì¼ì'] = df_hist.groupby('ë¬¼í’ˆê³ ìœ ë²ˆí˜¸')['ë³€ê²½ì¼ì'].shift(-1) - pd.Timedelta(days=1)
# í˜„ì¬ ìœ íš¨í•œ ìƒíƒœ(ë§ˆì§€ë§‰ ìƒíƒœ)ëŠ” 2099ë…„ê¹Œì§€
df_hist['ìœ íš¨ì¢…ë£Œì¼ì'] = df_hist['ìœ íš¨ì¢…ë£Œì¼ì'].fillna(CURRENT_STATUS_END_DATE)

# 3. ì†ì„± ì •ë³´ ê²°í•© (ìš´ìš©ëŒ€ì¥ì—ì„œ ë³€í•˜ì§€ ì•ŠëŠ” ì •ë³´ë“¤)
static_cols = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…','ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
]
df_static = df_op[static_cols].drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'])
df_scd_raw = pd.merge(df_hist, df_static, on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

# ë¶€ì„œ ì •ë³´ (Phase 2ì—ì„œ ë¶€ì„œ ì´ë™ ë¡œì§ì´ ì—†ìœ¼ë¯€ë¡œ ìš´ìš©ëŒ€ì¥ ë¶€ì„œ ì‚¬ìš©)
df_dept = df_op[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìš´ìš©ë¶€ì„œ']].drop_duplicates()
df_scd_raw = pd.merge(df_scd_raw, df_dept, on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

# ìƒíƒœê°’ ë§¤í•‘: ì´ë ¥ ë°ì´í„°ì˜ '(ë³€ê²½)ìš´ìš©ìƒíƒœ'ê°€ ê·¸ ë‹¹ì‹œì˜ ì‹¤ì œ ìƒíƒœì„
df_scd_raw['ìš´ìš©ìƒíƒœ'] = df_scd_raw['(ë³€ê²½)ìš´ìš©ìƒíƒœ']


# 4. ê·¸ë£¹í•‘ ë° ìˆ˜ëŸ‰ ì§‘ê³„ (Aggregation)
# ë¬¼í’ˆê³ ìœ ë²ˆí˜¸ë¥¼ ì œê±°í•˜ê³ , ë‚˜ë¨¸ì§€ ëª¨ë“  ì†ì„±ì´ ë™ì¼í•œ ê±´ë“¤ì„ ë¬¶ì–´ì„œ ìˆ˜ëŸ‰ì„ ì…‰ë‹ˆë‹¤.
# ê·¸ë£¹í•‘ ê¸°ì¤€: í™”ë©´ì— í‘œì‹œë  ëª¨ë“  ì†ì„± + ìœ íš¨ê¸°ê°„
group_cols_scd = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 
    'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ ',
    'ìœ íš¨ì‹œì‘ì¼ì', 'ìœ íš¨ì¢…ë£Œì¼ì'
]

# ë‚ ì§œ í¬ë§·íŒ… (ê·¸ë£¹í•‘ í‚¤ë¡œ ì“°ê¸° ìœ„í•´)
df_scd_raw['ìœ íš¨ì‹œì‘ì¼ì'] = df_scd_raw['ìœ íš¨ì‹œì‘ì¼ì'].dt.strftime('%Y-%m-%d')
df_scd_raw['ìœ íš¨ì¢…ë£Œì¼ì'] = df_scd_raw['ìœ íš¨ì¢…ë£Œì¼ì'].dt.strftime('%Y-%m-%d')

# ê·¸ í›„ NaN ì²˜ë¦¬
df_scd_raw = df_scd_raw.fillna('')

# ìˆ˜ëŸ‰ ì§‘ê³„ (size -> ìˆ˜ëŸ‰)
view_inventory_scd = df_scd_raw.groupby(group_cols_scd).size().reset_index(name='ìˆ˜ëŸ‰')

# 5. ìµœì¢… ì»¬ëŸ¼ ì •ë¦¬
final_scd_cols = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìˆ˜ëŸ‰', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ ',
    'ìœ íš¨ì‹œì‘ì¼ì', 'ìœ íš¨ì¢…ë£Œì¼ì'
]
view_inventory_scd = view_inventory_scd[final_scd_cols].copy()

view_inventory_scd.to_csv(os.path.join(SAVE_DIR, 'View_07_01_ë³´ìœ í˜„í™©_ì´ë ¥ê¸°ë°˜.csv'), index=False, encoding='utf-8-sig')

print("   -> [ì™„ë£Œ] 'View_07_01_ë³´ìœ í˜„í™©_ì´ë ¥ê¸°ë°˜.csv' ìƒì„±ë¨. (ê¸°ê°„ ì¡°íšŒìš©)")
# ---------------------------------------------------------
# 2. ë°ì´í„° ì •í•©ì„± ê²€ì¦ (Validation)
# ---------------------------------------------------------
print("\nğŸ” [Phase 3] ë°ì´í„° ì •í•©ì„± ê²€ì¦ ì‹œì‘")

# ê²€ì¦ 1: ì´ë ¥ ê¸°ë°˜ ë°ì´í„° ê²€ì¦ (ìµœì‹  ìƒíƒœê°€ ìš´ìš©ëŒ€ì¥ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€)
# 2099-12-31ì¼ì(í˜„ì¬ ìœ íš¨í•œ ìƒíƒœ)ë¥¼ í•„í„°ë§í•˜ì—¬ ìš´ìš©ëŒ€ì¥ê³¼ ë¹„êµ
current_snapshot = view_inventory_scd[view_inventory_scd['ìœ íš¨ì¢…ë£Œì¼ì'] == '2099-12-31']
total_op = len(df_op)
current_snapshot_qty = pd.to_numeric(
    current_snapshot['ìˆ˜ëŸ‰'],
    errors='coerce'
)
# ìˆ˜ëŸ‰ ìˆ«ì ë³€í™˜ ì‹œ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì¶”ê°€
coerced_mask = current_snapshot['ìˆ˜ëŸ‰'].notna() & current_snapshot_qty.isna()
if coerced_mask.any():
    sample_values = (
        current_snapshot.loc[coerced_mask, 'ìˆ˜ëŸ‰']
        .drop_duplicates()
        .astype(str)
        .head()
        .tolist()
    )
    print(f"âš ï¸ ê²½ê³ : ë¹„ìˆ«ì ìˆ˜ëŸ‰ {coerced_mask.sum()}ê±´")
    print(f"   ì˜ˆì‹œ ê°’: {sample_values}")

total_snap = current_snapshot_qty.sum(skipna=True)


print(f"1. ìµœì‹  ìƒíƒœ ë™ê¸°í™” ê²€ì¦: ìš´ìš©ëŒ€ì¥({total_op}) vs ì´ë ¥ìŠ¤ëƒ…ìƒ·({total_snap})")
if total_op == total_snap:
    print("   âœ… PASS: ì´ë ¥ ë°ì´í„°ì˜ ìµœì‹  ìƒíƒœê°€ ìš´ìš©ëŒ€ì¥ê³¼ ì •í™•íˆ ì¼ì¹˜í•©ë‹ˆë‹¤.")
else:
    print("   âŒ FAIL: ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œìƒ.")

# ê²€ì¦ 2: ë‚ ì§œ ë…¼ë¦¬ í™•ì¸ (ì·¨ë“ì¼ì < ë¶ˆìš©ì¼ì)
# ë¶ˆìš© ëª©ë¡ì—ì„œ ìƒ˜í”Œë§í•˜ì—¬ í™•ì¸
print("2. ë‚ ì§œ ë…¼ë¦¬ ê²€ì¦ (ì·¨ë“ì¼ì < ë¶ˆìš©ì¼ì)")
df_du_dates = df_du[['ì·¨ë“ì¼ì', 'ë¶ˆìš©ì¼ì']].apply(pd.to_datetime, errors='coerce')

valid_mask = (
    df_du_dates['ì·¨ë“ì¼ì'].notna() &
    df_du_dates['ë¶ˆìš©ì¼ì'].notna()
)

error_count = (
    df_du_dates.loc[valid_mask, 'ë¶ˆìš©ì¼ì'] <
    df_du_dates.loc[valid_mask, 'ì·¨ë“ì¼ì']
).sum()



if error_count == 0:
    print("   âœ… PASS: ëª¨ë“  ë°ì´í„°ê°€ ì‹œê°„ ìˆœì„œ(ì·¨ë“->ë¶ˆìš©)ë¥¼ ì¤€ìˆ˜í•©ë‹ˆë‹¤.")
else:
    print(f"   âŒ FAIL: {error_count}ê±´ì˜ ë°ì´í„°ì—ì„œ ì‹œê°„ ì—­ì „ í˜„ìƒ ë°œìƒ.")

# ê²€ì¦ 3: ë°˜ë ¤ ë°ì´í„° ê²©ë¦¬ í™•ì¸
# ìš´ìš©ëŒ€ì¥ì—ëŠ” 'í™•ì •'ëœ ê±´ë§Œ ìˆì–´ì•¼ í•˜ë¯€ë¡œ, 
# ë§Œì•½ ë°˜ë‚©/ë¶ˆìš©/ì²˜ë¶„ì—ì„œ 'ë°˜ë ¤'ëœ ê±´ì´ ìš´ìš©ìƒíƒœë¥¼ ë³€ê²½ì‹œì¼°ëŠ”ì§€ í™•ì¸
# (Phase 2 ë¡œì§ìƒ ë°˜ë ¤ë˜ë©´ ìƒíƒœ ë³€ê²½ ì•ˆ í•¨ -> ìš´ìš©ëŒ€ì¥ì—” ì´ì „ ìƒíƒœë¡œ ë‚¨ì•„ìˆì–´ì•¼ í•¨)
# ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì²˜ë¶„ ë¦¬ìŠ¤íŠ¸ì˜ 'ìŠ¹ì¸ìƒíƒœ'ê°€ 'í™•ì •'ì¸ ê²ƒë§Œ 'ì²˜ë¶„' ìƒíƒœì¸ì§€ í™•ì¸
print("3. ìƒíƒœ ë¡œì§ ê²€ì¦ (ì²˜ë¶„ í™•ì • ê±´)")
disposal_confirmed_ids = df_dp[df_dp['ìŠ¹ì¸ìƒíƒœ'] == 'í™•ì •']['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'].tolist()
op_disposed_rows = df_op[df_op['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'].isin(disposal_confirmed_ids)]
non_disposed_status = op_disposed_rows[op_disposed_rows['ìš´ìš©ìƒíƒœ'] != 'ì²˜ë¶„']

if len(non_disposed_status) == 0:
    print("   âœ… PASS: ì²˜ë¶„ í™•ì •ëœ ëª¨ë“  ë¬¼í’ˆì˜ ìš´ìš©ìƒíƒœê°€ 'ì²˜ë¶„'ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print(f"   âŒ FAIL: ì²˜ë¶„ í™•ì •ë˜ì—ˆìœ¼ë‚˜ ìƒíƒœê°€ ë³€ê²½ë˜ì§€ ì•Šì€ ê±´ì´ {len(non_disposed_status)}ê°œ ìˆìŠµë‹ˆë‹¤.")

print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("   ìƒì„±ëœ íŒŒì¼ ëª©ë¡:")
print("   - View_06_01_ë¶ˆìš©ë¬¼í’ˆë“±ë¡.csv")
print("   - View_07_01_ë³´ìœ í˜„í™©_ì´ë ¥ê¸°ë°˜.csv")