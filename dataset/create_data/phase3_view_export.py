import pandas as pd
import os
from pandas.errors import EmptyDataError  # ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ import

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOAD_DIR = os.path.join(BASE_DIR, "data_lifecycle") # ì›ì²œ ë°ì´í„°
SAVE_DIR = os.path.join(BASE_DIR, "data_view")      # ë·° ë°ì´í„° (create_data/data_view)
os.makedirs(SAVE_DIR, exist_ok=True) # data_view í´ë” ìƒì„±

# í˜„ì¬ ìœ íš¨í•œ ìƒíƒœë¥¼ ì˜ë¯¸í•˜ëŠ” ì¢…ë£Œì¼ (ë¬´ê¸°í•œ ìœ íš¨)
CURRENT_STATUS_END_DATE = pd.Timestamp('2099-12-31')

# ---------------------------------------------------------
# 0. ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
print("ğŸ“‚ [Phase 3] ì›ì²œ ë°ì´í„° ë¡œë“œ ì¤‘...")

def safe_read_csv(file_path):
    """íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ë¹„ì–´ìˆì§€ ì•Šì„ ë•Œë§Œ ë¡œë“œ, ì‹¤íŒ¨ ì‹œ ë¹ˆ DF ë°˜í™˜"""
    if not os.path.exists(file_path):
        return pd.DataFrame()
    try:
        return pd.read_csv(file_path)
    except EmptyDataError:
        return pd.DataFrame()

try:
    # Phase 2 ê²°ê³¼ë¬¼
    df_op = safe_read_csv(os.path.join(LOAD_DIR, '04_01_operation_master.csv'))
    df_rt = safe_read_csv(os.path.join(LOAD_DIR, '04_03_return_list.csv'))
    df_du = safe_read_csv(os.path.join(LOAD_DIR, '05_01_disuse_list.csv'))
    df_dp = safe_read_csv(os.path.join(LOAD_DIR, '06_01_disposal_list.csv'))
    df_hist = safe_read_csv(os.path.join(LOAD_DIR, '99_asset_status_history.csv'))
    
    # ìš´ìš© ëŒ€ì¥ì€ í•„ìˆ˜ì´ë¯€ë¡œ ë¹„ì–´ìˆìœ¼ë©´ ì¢…ë£Œ
    if df_op.empty:
        print("âŒ ì˜¤ë¥˜: '04_01_operation_master.csv' ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        exit()

    print(f"   - ìš´ìš© ë§ˆìŠ¤í„°: {len(df_op)}ê±´")

    # ë¦¬ë·°ì–´ ì§€ì  ì‚¬í•­: ê³¼ê±° ë¶€ì„œ ì •ë³´ ë³µì›ì„ ìœ„í•´ ìš´ìš©ì‹ ì²­ ì´ë ¥ ë¡œë“œ
    path_req = os.path.join(LOAD_DIR, '04_02_operation_req_list.csv')
    if os.path.exists(path_req):
        df_req = safe_read_csv(path_req)
    else:
        df_req = pd.DataFrame(columns=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ì‹ ì²­ì¼ì'])
        
    # ë°ì´í„° í”„ë ˆì„ ì „ì²´ì˜ NaN(ê²°ì¸¡ì¹˜)ë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì¹˜í™˜ (ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ)
    # ë‚ ì§œë‚˜ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ ë‘ì–´ì•¼ ì˜¤ë¥˜ê°€ ì•ˆ ë‚¨
    str_cols = ['ë¹„ê³ ', 'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ', 'ì‚¬ìœ ', 'ë¬¼í’ˆìƒíƒœ']
    
    for df in [df_op, df_rt, df_du, df_dp]:
        for col in str_cols:
            if col in df.columns:
                df[col] = df[col].fillna('')

except FileNotFoundError as e:
    print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Phase 1, 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”. ({e})")
    exit()
except Exception as e:
    print(f"âŒ CSV ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    exit()

# ---------------------------------------------------------
# 1. í™”ë©´ë³„ View CSV ìƒì„±
# ---------------------------------------------------------
print("âš™ï¸ [Phase 3] í™”ë©´ë³„ ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ View CSV ìƒì„± ì¤‘...")

# [04-01] ë¬¼í’ˆ ìš´ìš© - ë¬¼í’ˆê¸°ë³¸ì •ë³´ (Grouped View)
print("   - [04-01] ìš´ìš© í™”ë©´ìš© ê¸°ë³¸ì •ë³´ ì§‘ê³„ ì¤‘...")

group_cols_op = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ìº í¼ìŠ¤','ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
]

# ë°ì´í„° ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
if set(group_cols_op).issubset(df_op.columns):
    view_op_basic = df_op.groupby(group_cols_op).size().reset_index(name='ìˆ˜ëŸ‰')
    view_op_basic.to_csv(os.path.join(SAVE_DIR, 'View_04_01_ìš´ìš©_ê¸°ë³¸ì •ë³´.csv'), index=False, encoding='utf-8-sig')
else:
    print("   âš ï¸ ê²½ê³ : 04_01 íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# [06-01] ë¶ˆìš© ë¬¼í’ˆ ëª©ë¡
# ë³‘í•©ì— ì‚¬ìš©í•  Master ì •ë³´
master_cols = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë‚´ìš©ì—°ìˆ˜', 'ì·¨ë“ê¸ˆì•¡', 'ì·¨ë“ì¼ì', 'ì •ë¦¬ì¼ì', 'G2B_ëª©ë¡ëª…']
# df_duê°€ ë¹„ì–´ìˆê±°ë‚˜ ê¸°ë³¸ í‚¤ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë³‘í•© ëŒ€ì‹  ë¹ˆ ê²°ê³¼ë¥¼ ìƒì„±
if df_du.empty or 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸' not in df_du.columns or not set(master_cols).issubset(df_op.columns):
    print("   âš ï¸ ê²½ê³ : 06_01 íŒŒì¼ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°(df_du ë˜ëŠ” df_op)ê°€ ë¹„ì–´ìˆê±°ë‚˜ í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    base_cols = list(df_du.columns)
    # ë³‘í•© ì‹œ ì¶”ê°€ë  master_cols ì¤‘ ê¸°ë³¸ í‚¤ëŠ” ì œì™¸í•˜ê³ , ì•„ì§ ì—†ëŠ” ì»¬ëŸ¼ë§Œ ì¶”ê°€
    extra_cols = [c for c in master_cols if c != 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸' and c not in base_cols]
    view_du_item = pd.DataFrame(columns=base_cols + extra_cols)
else:
    df_master_info = df_op[master_cols].drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'])
    cols_to_merge = [c for c in master_cols if c == 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸' or c not in df_du.columns]
    view_du_item = pd.merge(df_du, df_master_info[cols_to_merge], on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

view_du_item.to_csv(os.path.join(SAVE_DIR, 'View_06_01_ë¶ˆìš©ë¬¼í’ˆëª©ë¡.csv'), index=False, encoding='utf-8-sig')

# [07-01] ë³´ìœ  í˜„í™© ì¡°íšŒ (SCD Type 2 History)
print("   - [07-01] ë³´ìœ  í˜„í™©(ê³¼ê±° ì‹œì  ì¡°íšŒìš©) ë°ì´í„° ìƒì„± ì¤‘...")

# [Fix] ë¦¬ë·° ë°˜ì˜: df_hist ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ (KeyError ë°©ì§€)
required_hist_cols = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë³€ê²½ì¼ì', '(ë³€ê²½)ìš´ìš©ìƒíƒœ']
group_cols_scd = [
    'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ìº í¼ìŠ¤',
    'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
    'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ìƒíƒœ', 'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 
    'ì·¨ë“ì •ë¦¬êµ¬ë¶„', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ ',
    'ìœ íš¨ì‹œì‘ì¼ì', 'ìœ íš¨ì¢…ë£Œì¼ì'
]

# ê°€ë“œ ì²˜ë¦¬: ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ìŠ¤í‚¤ë§ˆ ìƒì„±
if df_hist.empty or not set(required_hist_cols).issubset(df_hist.columns):
    print("     âš ï¸ ê²½ê³ : ì´ë ¥ ë°ì´í„°(df_hist)ê°€ ì—†ê±°ë‚˜ í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì–´ ë¹ˆ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    view_inventory_scd = pd.DataFrame(columns=group_cols_scd + ['ìˆ˜ëŸ‰'])

else:
    try:
        # 1. ì´ë ¥ ë°ì´í„° ì •ë ¬
        df_hist_proc = df_hist.copy()
        df_hist_proc['ë³€ê²½ì¼ì'] = pd.to_datetime(df_hist_proc['ë³€ê²½ì¼ì'], errors='coerce')
        # ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ í–‰ ì œê±° (NaT)
        df_hist_proc = df_hist_proc.dropna(subset=['ë³€ê²½ì¼ì'])
        df_hist_proc = df_hist_proc.sort_values(by=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë³€ê²½ì¼ì'])

        # 2. ìœ íš¨ ê¸°ê°„(Start ~ End) ìƒì„±
        df_hist_proc['ìœ íš¨ì‹œì‘ì¼ì'] = df_hist_proc['ë³€ê²½ì¼ì']
        df_hist_proc['ìœ íš¨ì¢…ë£Œì¼ì'] = df_hist_proc.groupby('ë¬¼í’ˆê³ ìœ ë²ˆí˜¸')['ë³€ê²½ì¼ì'].shift(-1) - pd.Timedelta(days=1)
        df_hist_proc['ìœ íš¨ì¢…ë£Œì¼ì'] = df_hist_proc['ìœ íš¨ì¢…ë£Œì¼ì'].fillna(CURRENT_STATUS_END_DATE)

        # 3. ì†ì„± ì •ë³´ ê²°í•©
        # ì •ì  ì •ë³´(ìš´ìš©ë¶€ì„œ í¬í•¨)ëŠ” ëª¨ë‘ df_opì—ì„œ ê°€ì ¸ì˜´
        static_cols = [
            'G2B_ëª©ë¡ë²ˆí˜¸', 'G2B_ëª©ë¡ëª…', 'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìº í¼ìŠ¤', 'ì·¨ë“ì¼ì', 'ì·¨ë“ê¸ˆì•¡', 'ì •ë¦¬ì¼ì', 
            'ë‚´ìš©ì—°ìˆ˜', 'ìŠ¹ì¸ìƒíƒœ', 'ì·¨ë“ì •ë¦¬êµ¬ë¶„','ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ë¹„ê³ '
        ]
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ë³‘í•©
        avail_static_cols = [c for c in static_cols if c in df_op.columns]
        df_static = df_op[avail_static_cols].drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'])
        
        df_scd_raw = pd.merge(df_hist_proc, df_static, on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

        # 3-2. ë¶€ì„œ ì •ë³´ ë³µì› (ë¦¬ë·° ë°˜ì˜)
        if not df_req.empty and {'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìš´ìš©ë¶€ì„œ', 'ìš´ìš©ì‹ ì²­ì¼ì'}.issubset(df_req.columns):
            dept_map = (
                df_req.sort_values('ìš´ìš©ì‹ ì²­ì¼ì')
                .drop_duplicates('ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', keep='last')[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ìš´ìš©ë¶€ì„œ']]
            )

            df_scd_raw = pd.merge(
                df_scd_raw,
                dept_map,
                on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸',
                how='left',
                suffixes=('', '_req')
            )

            # ìš´ìš©ë¶€ì„œ_req ì»¬ëŸ¼ì´ ì¡´ì¬í•  ë•Œë§Œ ë³´ì •
            if 'ìš´ìš©ë¶€ì„œ_req' in df_scd_raw.columns:
                if 'ìš´ìš©ë¶€ì„œ' in df_scd_raw.columns:
                    df_scd_raw['ìš´ìš©ë¶€ì„œ'] = (
                        df_scd_raw['ìš´ìš©ë¶€ì„œ']
                        .replace('', pd.NA)
                        .fillna(df_scd_raw['ìš´ìš©ë¶€ì„œ_req'])
                        .fillna('')
                    )
                else:
                    df_scd_raw['ìš´ìš©ë¶€ì„œ'] = df_scd_raw['ìš´ìš©ë¶€ì„œ_req'].fillna('')
                
                df_scd_raw = df_scd_raw.drop(columns=['ìš´ìš©ë¶€ì„œ_req'], errors='ignore')

        # 4. ìƒíƒœê°’ ë§¤í•‘ ë° í¬ë§·íŒ…
        df_scd_raw['ìš´ìš©ìƒíƒœ'] = df_scd_raw['(ë³€ê²½)ìš´ìš©ìƒíƒœ']
        df_scd_raw['ìœ íš¨ì‹œì‘ì¼ì'] = df_scd_raw['ìœ íš¨ì‹œì‘ì¼ì'].dt.strftime('%Y-%m-%d')
        df_scd_raw['ìœ íš¨ì¢…ë£Œì¼ì'] = df_scd_raw['ìœ íš¨ì¢…ë£Œì¼ì'].dt.strftime('%Y-%m-%d')
        df_scd_raw = df_scd_raw.fillna('')

        # 5. ê·¸ë£¹í•‘ ë° ìˆ˜ëŸ‰ ì§‘ê³„
        # ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì— ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ìœ¼ë¡œë§Œ ê·¸ë£¹í•‘ (KeyError ë°©ì§€)
        actual_group_cols = [c for c in group_cols_scd if c in df_scd_raw.columns]
        view_inventory_scd = df_scd_raw.groupby(actual_group_cols).size().reset_index(name='ìˆ˜ëŸ‰')
        
    except Exception as e:
        print(f"     âŒ ì´ë ¥ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        view_inventory_scd = pd.DataFrame(columns=group_cols_scd + ['ìˆ˜ëŸ‰'])

view_inventory_scd.to_csv(os.path.join(SAVE_DIR, 'View_07_01_ë³´ìœ í˜„í™©_ì´ë ¥ê¸°ë°˜.csv'), index=False, encoding='utf-8-sig')
# ---------------------------------------------------------
# SCD (ì´ë ¥ ì¶”ì ) ë°ì´í„° ìƒì„±
# ---------------------------------------------------------
print("     SCD (Slowly Changing Dimension) ìƒì„±...")

# [Copilot Fix] ì´ë ¥ ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
if df_hist.empty:
    print("      âš ï¸ ì´ë ¥ ë°ì´í„°ê°€ ì—†ì–´ SCD ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    # ë¹ˆ DataFrame ìƒì„± (ì €ì¥ ì‹œ ì—ëŸ¬ ë°©ì§€ìš© ì»¬ëŸ¼ ì •ì˜)
    cols_scd = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'Start_Date', 'End_Date', 'Is_Current', 'ìš´ìš©ìƒíƒœ', 'ì‚¬ìœ ', 'ê´€ë¦¬ì']
    df_scd = pd.DataFrame(columns=cols_scd)

else:
    # 1. ì´ë ¥ ë°ì´í„° ì •ë ¬
    # 'ë³€ê²½ì¼ì' ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸ í›„ ë³€í™˜
    if 'ë³€ê²½ì¼ì' in df_hist.columns:
        df_hist['ë³€ê²½ì¼ì'] = pd.to_datetime(df_hist['ë³€ê²½ì¼ì'])
        df_hist = df_hist.sort_values(by=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë³€ê²½ì¼ì'])
        
        scd_list = []

        for asset_id, group in df_hist.groupby('ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'):
            group = group.sort_values('ë³€ê²½ì¼ì')
            prev_row = None
            
            for idx, row in group.iterrows():
                curr_date = row['ë³€ê²½ì¼ì']
                
                # ì´ì „ ì´ë ¥ ë‹«ê¸°
                if prev_row is not None:
                    scd_list.append({
                        'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸': asset_id,
                        'Start_Date': prev_row['ë³€ê²½ì¼ì'],
                        'End_Date': curr_date - pd.Timedelta(days=1),
                        'Is_Current': False,
                        'ìš´ìš©ìƒíƒœ': prev_row['(ë³€ê²½)ìš´ìš©ìƒíƒœ'],
                        'ì‚¬ìœ ': prev_row['ì‚¬ìœ '],
                        'ê´€ë¦¬ì': prev_row['ê´€ë¦¬ìëª…']
                    })
                
                prev_row = row
            
            # ë§ˆì§€ë§‰ ì´ë ¥ (í˜„ì¬ ìƒíƒœ)
            if prev_row is not None:
                scd_list.append({
                    'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸': asset_id,
                    'Start_Date': prev_row['ë³€ê²½ì¼ì'],
                    'End_Date': CURRENT_STATUS_END_DATE, # 2099-12-31
                    'Is_Current': True,
                    'ìš´ìš©ìƒíƒœ': prev_row['(ë³€ê²½)ìš´ìš©ìƒíƒœ'],
                    'ì‚¬ìœ ': prev_row['ì‚¬ìœ '],
                    'ê´€ë¦¬ì': prev_row['ê´€ë¦¬ìëª…']
                })
        
        df_scd = pd.DataFrame(scd_list)
        print(f"      - SCD ì´ë ¥ ë³€í™˜ ì™„ë£Œ: {len(df_scd)}ê±´")
        
    else:
        print("      âŒ ì˜¤ë¥˜: ì´ë ¥ ë°ì´í„°ì— 'ë³€ê²½ì¼ì' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        cols_scd = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'Start_Date', 'End_Date', 'Is_Current', 'ìš´ìš©ìƒíƒœ', 'ì‚¬ìœ ', 'ê´€ë¦¬ì']
        df_scd = pd.DataFrame(columns=cols_scd)

# SCD ì €ì¥
df_scd.to_csv(os.path.join(SAVE_DIR, 'asset_scd_history.csv'), index=False, encoding='utf-8-sig')
# ---------------------------------------------------------
# 2. ë°ì´í„° ì •í•©ì„± ê²€ì¦ (Validation)
# ---------------------------------------------------------
print("\nğŸ” [Phase 3] ë°ì´í„° ì •í•©ì„± ê²€ì¦ ì‹œì‘")

# ê²€ì¦ 1: ì´ë ¥ ê¸°ë°˜ ë°ì´í„° ê²€ì¦
current_snapshot = view_inventory_scd[
    view_inventory_scd['ìœ íš¨ì¢…ë£Œì¼ì'] == CURRENT_STATUS_END_DATE.strftime('%Y-%m-%d')
]
total_op = len(df_op)
current_snapshot_qty = pd.to_numeric(current_snapshot['ìˆ˜ëŸ‰'], errors='coerce').sum()

print(f"1. ìµœì‹  ìƒíƒœ ë™ê¸°í™” ê²€ì¦: ìš´ìš©ëŒ€ì¥({total_op}) vs ì´ë ¥ìŠ¤ëƒ…ìƒ·({int(current_snapshot_qty)})")
if total_op == current_snapshot_qty:
    print("   âœ… PASS: ì¼ì¹˜í•©ë‹ˆë‹¤.")
else:
    print("   âŒ FAIL: ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œìƒ.")

# ê²€ì¦ 2: ë‚ ì§œ ë…¼ë¦¬ í™•ì¸
if not df_du.empty:
    # df_duì— ì·¨ë“ì¼ìê°€ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ df_master_infoì™€ ë³‘í•©ëœ view_du_item ì‚¬ìš© ê¶Œì¥
    df_check = view_du_item.copy()
    df_check['ì·¨ë“ì¼ì'] = pd.to_datetime(df_check['ì·¨ë“ì¼ì'], errors='coerce')
    df_check['ë¶ˆìš©ì¼ì'] = pd.to_datetime(df_check['ë¶ˆìš©ì¼ì'], errors='coerce')

    # NaT ì—¬ë¶€ ì§‘ê³„
    invalid_mask = df_check['ì·¨ë“ì¼ì'].isna() | df_check['ë¶ˆìš©ì¼ì'].isna()
    invalid_cnt = invalid_mask.sum()

    # ìœ íš¨ ë‚ ì§œë§Œ ë¹„êµ
    valid_df = df_check[~invalid_mask]
    error_cnt = (valid_df['ë¶ˆìš©ì¼ì'] < valid_df['ì·¨ë“ì¼ì']).sum()

    print("2. ë‚ ì§œ ë…¼ë¦¬ ê²€ì¦ (ì·¨ë“ì¼ì < ë¶ˆìš©ì¼ì)")
    if error_cnt == 0:
        print("   âœ… PASS: ì‹œê°„ ìˆœì„œ ì •ìƒ.")
    else:
        print(f"   âŒ FAIL: {error_cnt}ê±´ ì‹œê°„ ì—­ì „.")

    if invalid_cnt > 0:
        print(f"   âš ï¸ ì°¸ê³ : ë‚ ì§œ ëˆ„ë½/í˜•ì‹ ì˜¤ë¥˜ {invalid_cnt}ê±´ ì¡´ì¬.")
else:
    print("   â„¹ï¸ ë¶ˆìš© ë°ì´í„°ê°€ ì—†ì–´ ê²€ì¦ ê±´ë„ˆëœ€.")

# [Fix] ì²˜ë¶„ ìƒíƒœ ë™ê¸°í™” ê²€ì¦ (ìŠ¹ì¸ ìƒíƒœ ê³ ë ¤)
if not df_dp.empty:
    # ì²˜ë¶„ ëª©ë¡ ì¤‘ 'í™•ì •'ì¸ ê±´ë“¤ë§Œ ì¶”ì¶œ
    confirmed_disposal_ids = df_dp[df_dp['ìŠ¹ì¸ìƒíƒœ'] == 'í™•ì •']['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'].unique()
    
    # ìš´ìš©ëŒ€ì¥ì—ì„œ í•´ë‹¹ ID ì¡°íšŒ
    if len(confirmed_disposal_ids) == 0:
        # í™•ì •ëœ ì²˜ë¶„ ê±´ì´ ì—†ëŠ” ê²½ìš°
        print("3. ì²˜ë¶„ ìƒíƒœ(í™•ì •ê±´): â„¹ï¸ í™•ì •ëœ ì²˜ë¶„ ê±´ì´ ì—†ì–´ ê²€ì¦ ê±´ë„ˆëœ€.")
    
    # ìƒíƒœê°€ 'ì²˜ë¶„'ì´ ì•„ë‹Œ ê²ƒ ì¹´ìš´íŠ¸
    else:
        op_status = df_op[df_op['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'].isin(confirmed_disposal_ids)]['ìš´ìš©ìƒíƒœ']
        err_cnt = (op_status != 'ì²˜ë¶„').sum()
        print(f"3. ì²˜ë¶„ ìƒíƒœ(í™•ì •ê±´): {'âœ… PASS' if err_cnt == 0 else f'âŒ FAIL ({err_cnt}ê±´ ë¯¸ë°˜ì˜)'}")
    
    # ëŒ€ê¸°/ë°˜ë ¤ ìƒíƒœì¸ ê±´ìˆ˜ ì¶œë ¥ (ID ê¸°ì¤€ì´ ì•„ë‹Œ Row ê¸°ì¤€ ì§‘ê³„)
    # ê¸°ì¡´: len(df_dp) - len(confirmed_ids) -> ì¤‘ë³µ IDë‚˜ ë¡œì§ ì˜¤ë¥˜ ê°€ëŠ¥ì„± ìˆìŒ
    pending_cnt = (df_dp['ìŠ¹ì¸ìƒíƒœ'] != 'í™•ì •').sum()
    print(f"   (ì°¸ê³ ) ì§„í–‰ ì¤‘ì¸ ì²˜ë¶„ ê±´: {pending_cnt}ê±´")

print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")